<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Automation Archives - Tungsten Fabric</title>
	<atom:link href="https://tungsten.io/category/automation/feed/" rel="self" type="application/rss+xml" />
	<link>https://tungsten.io/category/automation/</link>
	<description>multicloud multistack SDN</description>
	<lastBuildDate>Mon, 09 Jan 2017 00:03:24 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.4.1</generator>

<image>
	<url>https://tungsten.io/wp-content/uploads/sites/73/2018/03/cropped-TungstenFabric_Stacked_Gradient_3000px-150x150.png</url>
	<title>Automation Archives - Tungsten Fabric</title>
	<link>https://tungsten.io/category/automation/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Automating Contrail Cloud Solution</title>
		<link>https://tungsten.io/automating-contrail-cloud-solution/</link>
		
		<dc:creator><![CDATA[Ramanathan Sethuraman]]></dc:creator>
		<pubDate>Mon, 09 Jan 2017 00:03:24 +0000</pubDate>
				<category><![CDATA[Automation]]></category>
		<category><![CDATA[Cloud]]></category>
		<category><![CDATA[Network Services]]></category>
		<category><![CDATA[OpenStack]]></category>
		<guid isPermaLink="false">http://www.opencontrail.org/?p=7279</guid>

					<description><![CDATA[Executive summary: Contrail Cloud solution is an open cloud network automation product that uses software-defined networking (SDN) technology to orchestrate the creation of virtual networks with high scalability. It exposes a set...]]></description>
										<content:encoded><![CDATA[<h3>Executive summary:</h3>
<p>Contrail Cloud solution is an open cloud network automation product that uses software-defined networking (SDN) technology to orchestrate the creation of virtual networks with high scalability. It exposes a set of REST APIs for northbound interaction with cloud orchestration tools, as well as other applications. Contrail Cloud solution has multiple components like Contrail controller, Openstack controller and vRouters.</p>
<p>This product creates Virtual Machines on the compute nodes, attach Virtual Machine to the virtual network and connect the Virtual Machine to the storage.</p>
<p>This Document gives details on REST APIs to automate the following,</p>
<ul>
<li>Verifying hypervisor status</li>
<li>Create Virtual Machine or delete Virtual Machine</li>
<li>Create virtual Networks</li>
<li>Attach Virtual Machine to virtual network</li>
<li>Verifying Virtual Machine status</li>
<li>Get information about existing Virtual Machines</li>
</ul>
<h3>Description:</h3>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2017/01/Automating_Contrail_Cloud_Platform_Image1.jpg"><img fetchpriority="high" decoding="async" class="alignnone size-full wp-image-7280" src="http://www.opencontrail.org/wp-content/uploads/2017/01/Automating_Contrail_Cloud_Platform_Image1.jpg" alt="" width="459" height="433" data-id="7280" /></a></p>
<p>In contrail cloud solution Openstack server is responsible for creation of Virtual Machines.Openstack</p>
<p>server has inventory of all the Hypervisors.When a VM creation is requested through openstack Horizon GUI or through RESTAPI commands,NOVA component in openstack controller will connect to the Hypervisor (which has sufficient resources to create VM) and request for VM creation.</p>
<p>After VM is created, NEUTRON component in Openstack controller will connect to the Contrail controller and request for attaching the VM to the specefic Virtual Network.Contrail controller will then connect to the vrouter in the  Hypervisor (through XMPP protocol) and request for routing instance creation for the specefic virtual network.The same sequence operation repeated for each VM creation.</p>
<p>When the VMs are created on multiple hypervisors.They exchange routes between them.Then MPLS-OVER-GRE/MPLS-OVER-UDP Tunnels created between them.</p>
<p>RESTAPIs can be used for automating VM creation, VM deletion and other operations described.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2017/01/Automating_Contrail_Cloud_Platform_Image2.jpg"><img decoding="async" class="alignnone size-full wp-image-7281" src="http://www.opencontrail.org/wp-content/uploads/2017/01/Automating_Contrail_Cloud_Platform_Image2.jpg" alt="" width="696" height="492" data-id="7281" /></a></p>
<p>This picture shows the implementation details of Contrail cloud solution.In this topology PE2 &amp; PE3 will be acting as local Datacenter gateway.PE1 will be the remote Datacenter gateway.</p>
<p>All compute nodes, controllers are attached to IP fabric.The IP Fabric is not aware of the virtual Networks to which the virtual machines are attached.There is no need for the IP fabric to know virtual network details.Between PE2 (&amp;PE3) and compute nodes and between the compute nodes TUNNEL overlays is implemented.So all traffic between compute nodes to PE2/PE3 or between compute nodes will be encapsulated with TUNNEL header.IP fabric is aware of the IP addresses present in the Tunnel header(as these IP addresses are part of underlay/IP fabric network.</p>
<p>Contrail controllers will be managing the compute nodes (vRouters) using XMPP.PE2 &amp;PE3  will talk to Contrail controllers with BGP.The vRouters in contrail cloud will act similar to PE router in L3 VPN environment.</p>
<p>When a VM in a vRouter need to send traffic to VM in another vRouter in the same datacenter,</p>
<p>the source vRouter will encapsulate the packets with Tunnel header and then forward it to the IP fabric.After the destination vRouter receives the packet it will decapsulate the packets and forward it to the VM.</p>
<p>When vRouter need to send traffic to vRouters in another datacenter it will encapulate packets with Tunnel header and forward it to PE2 or PE3.PE2 or PE3 will decapsulate the MPLS-OVER-UDP header and then encapsulate it with MPLS headers and forward it to PE1.PE1 decapsulate MPLS header and forward the packets to the node in remote Datacenter.</p>
<h3>Automating Contrail/Openstack Controller:</h3>
<p>This section gives details on Contrail/Openstack controller Automation.A sample perl code with RESTAPI details given for each operations like virtual network creation,VM creation,VM deletion etc..Perl module LWP::UserAgent and use JSON qw( decode_json encode_json) should be sourced for this.</p>
<h4>Virtual Machine creation:</h4>
<p><strong>OpenStack Token-id and Tenant id:</strong></p>
<p>This section gives details on automating VM creation.Before starting VM creation we need to get the token-id and tenant id from the openstack controller.This token id is required to execute any operational commands in the openstack controller.Tenant id is required to find the right openstack project.The sample code given below gives details on this . The Openstack component keystone provides this token-id.</p>
<p>Keystone is the identity service used by OpenStack for authentication (authN) and high-level authorization (authZ). It currently supports token-based authN and user-service authorization.</p>
<p>In this sample code “$OS_tenant_name” is the project name.This name can be found on openstack Horizon GUI(identity-&gt;Projects).Project name is required to find the correct tenant id.The “$CMDpath” shows  the syntax of RESTAPI command to get token-id from openstack controller.The tenant id and token id collected here will be used in next steps.</p>
<pre><span style="font-family: 'courier new', courier;">my openstack_ip = ‘1.1.1.1’;
      	     	my  $KEYSTONEport     =  "5000";               
        		my $OS_tenant_name = "PROJECTNAME";
        		my $OS_user = "admin";
        		my $OS_password = ‘xxxxxx’;
                 	my $CMDpath= "/v2.0/tokens";
        	my $APIport=$KEYSTONEport;
        	my $url= "http://".$openstack_ip.":".$APIport.$CMDpath;
             my $body =
        	{
               	"auth"   =&gt;
                      	   {
                         	       "tenantName"  =&gt; "$OS_tenant_name",
                               	 "passwordCredentials" =&gt;
                                                {
                                              	  "username"  =&gt; "$OS_user",
                                              	  "password"  =&gt; "$OS_password"
                                                }
                          }                     
         };               
        	my $request  = HTTP::Request-&gt;new( POST =&gt; $url );
        	my $bjson = encode_json $body;
        	$request-&gt;content_type("application/json");
        	$request-&gt;authorization_basic( "$OS_user", "$OS_password" );
        	$request-&gt;content($bjson);
        	my $http = LWP::UserAgent-&gt;new-&gt;request($request);
        	my @y = $http-&gt;{_content};
        	my $mes         = JSON::decode_json($y[0]);
         
        	my $token_id = $mes-&gt;{'access'}{'token'}{'id'};
        	my $token_exp = $mes-&gt;{'access'}{'token'}{'expires'};
        	my $tenant_id = $mes-&gt;{'access'}{'token'}{'tenant'}{'id'};
        	print("\n\n *******  token_id is $token_id and token_exp is $token_exp and tenant_id is $tenant_id ******* \n\n");</span></pre>
<p><strong>Verifying Hypervisor status:</strong></p>
<p>Before going to next step we need to verify the status of compute nodes(Hypervisors).Before creating the VM,the Hypervisors should be Up and running.The RESTAPI command &#8220;/v1.1/&#8221;.$tenant_id.&#8221;/os-services&#8221; provides the status of the hypervisors.This is equivalent to “nova service-list command(the output given below).</p>
<pre><span style="font-family: 'courier new', courier;">my $NOVAport         =  "8774";
       $CMDpath= "/v1.1/".$tenant_id."/os-services";
        $APIport=$NOVAport;
        $url= "http://".$cont_ip.":".$APIport.$CMDpath;
        $request  = HTTP::Request-&gt;new( GET =&gt; $url );
        $request-&gt;header('content-type' =&gt; 'application/json');
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);
        @y = $http-&gt;{_content};
        print Dumper($http);    
        $mes         = JSON::decode_json($y[0]);
        my $len = @{$mes-&gt;{"services"}};          
        my %server_to_netaddr_hash;
        my %test;
        my $servername;
        my $state;
        my $status; 
        my $hostcount=0;
        for (my $x = 0; $x&lt; $len ; ++$x) { $servername = $mes-&gt;{"services"}[$x]{"host"};
                        if( ($servername =~/vmg\d+/) || ($servername =~/vm\d+/) ) {
	        $state = $mes-&gt;{"services"}[$x]{"state"};
                         my $status = $mes-&gt;{"services"}[$x]{"status"};
                         if ($state ne "up" || $status ne "enabled") {
        print("\n\n *******  status or state of host $servername is not correct.The state is $state and status is $status ******* \n\n");
         return JT::FALSE;
                        }
        print ("\n\n *******  status or state of the compute node $servername is correct The state is $state and status is $status ******* \n\n");
                    $hostcount++;

                   }
	}

root@server01:~# nova service-list
+----+------------------+--------------+----------+---------+-------+----------------------------+-----------------+
| Id | Binary           | Host         | Zone     | Status  | State | Updated_at                 | Disabled Reason |
+----+------------------+--------------+----------+---------+-------+----------------------------+-----------------+
| 1  | nova-scheduler   | server1 | internal | enabled | up    | 2016-12-09T21:32:39.000000 | -               |
| 2  | nova-console     |  server1 | internal | enabled | up    | 2016-12-09T21:32:42.000000 | -               |
| 3  | nova-consoleauth | server1 | internal | enabled | up    | 2016-12-09T21:32:42.000000 | -               |
| 4  | nova-conductor   | server1 | internal | enabled | up    | 2016-12-09T21:32:38.000000 | -               |
| 6  | nova-compute     | vm6          | nova     | enabled | up    | 2016-12-09T21:32:38.000000 | -               |
| 7  | nova-compute     | vm7          | nova     | enabled | up    | 2016-12-09T21:32:35.000000 | -               |
| 8  | nova-compute     | vm8          | nova     | enabled | up    | 2016-12-09T21:32:38.000000 | -               |
| 9  | nova-compute     | vm9          | nova     | enabled | up    | 2016-12-09T21:32:33.000000 | -               |
| 10 | nova-compute     | vm10         | nova     | enabled | up    | 2016-12-09T21:32:41.000000 | -               |
| 11 | nova-compute     | vm11         | nova     | enabled | up    | 2016-12-09T21:32:41.000000 | -               |
| 12 | nova-compute     | vm12         | nova     | enabled | up    | 2016-12-09T21:32:33.000000 | -               |
| 13 | nova-compute     | vm13         | nova     | enabled | up    | 2016-12-09T21:32:37.000000 | -               |
| 14 | nova-compute     | vm14         | nova     | enabled | up    | 2016-12-09T21:32:41.000000 | -               |
| 15 | nova-compute     | vm15         | nova     | enabled | up    | 2016-12-09T21:32:39.000000 | -               |
| 16 | nova-compute     | vm16         | nova     | enabled | up    | 2016-12-09T21:32:42.000000 | -               |
| 17 | nova-compute     | vm17         | nova     | enabled | up    | 2016-12-09T21:32:33.000000 | -               |
| 18 | nova-compute     | vm18         | nova     | enabled | up    | 2016-12-09T21:32:40.000000 | -               |
+----+------------------+--------------+----------+---------+-------+----------------------------+-----------------+
root@ server01:~# </span></pre>
<p><strong>Creating Virtual Network:</strong></p>
<p>The next step is to create virtual Network. Virtual network has to be created before creating VM.</p>
<p>To create virtual Network the following information is required.</p>
<ul>
<li>Network segment address and netmask</li>
<li>Gateway address</li>
<li>Network name</li>
<li>Route-target attached to this network</li>
<li>Project name (collected from openstack horizon GUI)</li>
<li>Token-id (as explained in previous step)</li>
</ul>
<p>To create virtual network ,the RESAPI command &#8220;/virtual-networks&#8221; is executed on the contrail controller.Port number 8082 is used for this.The correct project name should be added here where it says &#8220;PROJECTNAME&#8221;.”nova net-list” shows the network created as shown below.</p>
<pre><span style="font-family: 'courier new', courier;">$netname="net$i";
		$cont_ip=”1.1.1.1”;
		$target="target:64512:$value";
		$gateway="100.$n.$m.1";
		$pool = "100.$n.$m.0";
       		 $CMDpath = "/virtual-networks";
        		$APIport="8082";
       		 $url= "http://".$cont_ip.":".$APIport.$CMDpath;
          		$body =
              		{
               			"virtual-network"=&gt;
                 			  {
                  				 "parent_type"=&gt; "project",
                 				  "fq_name"=&gt; [
                             			 "default-domain",
                              			 "PROJECTNAME",
                              			  	$netname ],

                    			"route_target_list"=&gt;
                               		 {
                                			 "route_target"=&gt; [
								$target
							      ]
				  },

				"network_ipam_refs"=&gt; [{
                                         					  "attr"=&gt; {
                                                 				   	  "ipam_subnets"=&gt; [{
                                                                 				     "subnet"=&gt; {
                                                                                	  	 "gateway_ip" =&gt; $gateway,
                                                                                 		 "ip_prefix"=&gt; $pool,
                                                                                 		"ip_prefix_len"=&gt; 24}}]},
                                          					  "to"=&gt; [
                                                				     	"default-domain",
                                                    				     	"default-project",
                                                      				 "default-network-ipam"]}]}
            			   };

		$request  = HTTP::Request-&gt;new( POST =&gt; $url );
        		$bjson = encode_json $body;
       	 	$request-&gt;content_type("application/json");
       	 	$request-&gt;header('x-auth-token' =&gt; $token_id);
       	 	$request-&gt;content($bjson);
        		$http = LWP::UserAgent-&gt;new-&gt;request($request);

root@server1:~# nova net-list
+--------------------------------------+-------------------------+------+
| ID                                   | Label                   | CIDR |
+--------------------------------------+-------------------------+------+
| 363b4323-69d3-404a-b7b2-6587b4507479 | net6                    | None |
| 274b0b81-52be-48f9-8888-0c6be1d910c2 | net9                    | None |
| 72f26b86-f0bf-44c0-aadb-5f94c34b5eeb | net4                    | None |
| 72be70e4-c0d8-46ce-be8c-33d80f095c5a | default-virtual-network | None |
| aa0f528e-f276-4d5a-a02f-bb02f7289c9c | net10                   | None |
| ce1e9035-9c4d-49de-a867-2f4a27bd5691 | net13                   | None |
| b8599366-f1c0-4c2f-bab2-34533902466d | net12                   | None |
| b8543c48-872d-4e25-9de7-658f304c032a | net7                    | None |
| 34168c65-a4c8-439a-beda-3c7a1f380176 | net3                    | None |
| 7a244326-fc1e-416c-98fb-cc073f8762a0 | test                    | None |
| e7b4e0b9-6fc9-497f-9899-4e2aa344a97b | net11                   | None |
| d669a490-53f4-4fac-bed2-b79fe8538eae | __link_local__          | None |
| f5307953-9490-4da6-b365-7173035d69d3 | net5                    | None |
| a9eac604-a634-43df-8b9f-ea7258941313 | net8                    | None |
| a8363373-548d-4f78-8366-bd0277be8b80 | net1                    | None |
| c4d757cb-d2ab-4334-8e80-029cb0c31610 | ip-fabric               | None |
| fac53b08-59e7-45c6-9ef6-6007160979bb | net2                    | None |
+--------------------------------------+-------------------------+------+
root@ server1:~# </span></pre>
<p><strong>VM Flavor id/VM Image id/virtual Network id Details:</strong></p>
<p>Before creating the VM we need the following information.There are separate RESTAPI commands available to collect each of this information.</p>
<ul>
<li>VM name</li>
<li>VM flavor id</li>
<li>VM image id</li>
<li>Virtual network id</li>
<li>VM security group</li>
<li>Tenant name( or project name)</li>
</ul>
<p><strong>VM Flavor id:</strong></p>
<p>To get the VM flavor id the following code is used.The RESTAPI command &#8220;/v1.1/&#8221;.$tenant_id.&#8221;/flavors&#8221; returns the VM flavor id.This RESTAPI command is handled by NOVA component of OpenStack controller.</p>
<pre><span style="font-family: 'courier new', courier;">My $NOVAport         =  "8774";
           My $openstack_ip        =”1.1.1.1”;
	my $headers = "{ 'Content-Type' : 'application/json', 'Accept'  :  'application/json' , 'ser-Agent'  : 'python-novaclient', 'X-Auth-Token'   :    $token_id}";
        $CMDpath= "/v1.1/".$tenant_id."/flavors";
        $APIport=$NOVAport;
        $url= "http://". $openstack_ip.":".$APIport.$CMDpath;
        $request  = HTTP::Request-&gt;new( GET =&gt; $url );
        $request-&gt;header('content-type' =&gt; 'application/json');
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);
        @y = $http-&gt;{_content};
        $mes         = JSON::decode_json($y[0]);
        my $len = @{$mes-&gt;{'flavors'}};
        my $flavor_id;
        for (my $x = 0; $x&lt; $len ; ++$x) { if ($mes-&gt;{'flavors'}[$x]{'name'} eq $add_vm_flavor) {
                        $flavor_id = $mes-&gt;{'flavors'}[$x]{'id'};
                        last;
                }
        }
        print ( "\n\n *******  image id for $add_vm_flavor is $flavor_id ******* \n\n");</span></pre>
<p><strong>VM image id:</strong></p>
<p>To get the image id this code is used.The RESTAPI command &#8220;/v1.1/&#8221;.$tenant_id.&#8221;/images&#8221;returns the image id.This RESTAPI command is handled by NOVA component of openstack controller.</p>
<pre><span style="font-family: 'courier new', courier;">my $headers = "{ 'Content-Type' : 'application/json', 'Accept'  :  'application/json' , 'ser-Agent'  : 'python-novaclient', 'X-Auth-Token'   :    $token_id}";
        $CMDpath= "/v1.1/".$tenant_id."/images";
        $APIport=$NOVAport;
        $url= "http://".$cont_ip.":".$APIport.$CMDpath;
        $request  = HTTP::Request-&gt;new( GET =&gt; $url );
        $request-&gt;header('content-type' =&gt; 'application/json');
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);
        @y = $http-&gt;{_content};
        $mes         = JSON::decode_json($y[0]);
        my $len = @{$mes-&gt;{'images'}};
        my $image_id;
        for (my $x = 0; $x&lt; $len ; ++$x) { if ($mes-&gt;{'images'}[$x]{'name'} eq $add_vm_image ) {
                        $image_id = $mes-&gt;{'images'}[$x]{'id'};
                        last;
                }
        }
        print ("\n\n *******  image id for $add_vm_image is $image_id ******* \n\n");</span></pre>
<p><strong>Virtual Network ID:</strong></p>
<p>The RESTAPI command &#8220;/v1.1/&#8221;.$tenant_id.&#8221;/os-tenant-networks&#8221; returns the virtual network id.This RESTAPI command is handled by NOVA component of openstack controller.The network id of the networkname “$add_vm_net” can be identified by this code.</p>
<pre><span style="font-family: 'courier new', courier;">my $headers = "{ 'Content-Type' : 'application/json', 'Accept'  :  'application/json' , 'ser-Agent'  : 'python-novaclient', 'X-Auth-Token'   :    $token_id}";
        $CMDpath= "/v1.1/".$tenant_id."/os-tenant-networks";
        $APIport=$NOVAport;
        $url= "http://".$cont_ip.":".$APIport.$CMDpath;
        $request  = HTTP::Request-&gt;new( GET =&gt; $url );
        $request-&gt;header('content-type' =&gt; 'application/json');
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);
        @y = $http-&gt;{_content};
        $mes         = JSON::decode_json($y[0]);
        my $len = @{$mes-&gt;{'networks'}};
        my $network_id;
        for (my $x = 0; $x&lt; $len ; ++$x) { if ($mes-&gt;{'networks'}[$x]{'label'} eq $add_vm_net ) {
                        $network_id = $mes-&gt;{'networks'}[$x]{'id'};
                        last;
                }
        }
        print ("\n\n *******  networks id for $add_vm_net is $network_id ******* \n\n");</span></pre>
<p><strong>VM creation:</strong></p>
<p>Now we reached the final step to create VM.The RESTAPI &#8220;/v1.1/&#8221;.$tenant_id.&#8221;/servers&#8221; creates the VM.</p>
<p>The VM name,image id ,flavor id and security group name are required to run this RESTAPI command.</p>
<pre><span style="font-family: 'courier new', courier;">$headers = "{ 'Content-Type' : 'application/json', 'Accept' : 'application/json', 'ser-Agent' : 'python-novaclient', 'X-OpenStack-Nova-API-Version': '2.11', 'X-Auth-Token' : $token_id}";
        $CMDpath = "/v1.1/".$tenant_id."/servers";
        $APIport=$NOVAport;
        $url= "http://".$cont_ip.":".$APIport.$CMDpath;
        $body =
        {       "server" =&gt;
                         {
                                "name" =&gt; "$add_vm_name",
                                "imageRef" =&gt; "$image_id",
                                "flavorRef" =&gt; "$flavor_id",
                                "max_count" =&gt; 1,
                                "min_count" =&gt; 1,
                                "networks" =&gt; [{
                                                "uuid" =&gt; "$network_id"
                                }],
                                "security_groups" =&gt; [{
                                                "name" =&gt; "$add_vm_secgroup"
                                }]
                        }
        };
        $request  = HTTP::Request-&gt;new( POST =&gt; $url );
        $bjson = encode_json $body;
        $request-&gt;content_type("application/json");
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $request-&gt;content($bjson);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);</span></pre>
<p><strong>VM status verification:</strong></p>
<p>After creating VM the status of the VM can be verified by the RESTAPI command &#8220;/v1.1/&#8221;.$tenant_id.&#8221;/servers/detail&#8221;.This sample code gives details on how to verify status of a VM.It checks for vm_state to be active and power_state to be 1.This RESTAPI command is equivalent to nova list command shown below.</p>
<pre><span style="font-family: 'courier new', courier;">$CMDpath= "/v1.1/".$tenant_id."/servers/detail";
        $APIport=$NOVAport;
        $url= "http://".$cont_ip.":".$APIport.$CMDpath;
        $request  = HTTP::Request-&gt;new( GET =&gt; $url );
        $request-&gt;header('content-type' =&gt; 'application/json');
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);
        @y = $http-&gt;{_content};
        print Dumper($http);
        $mes         = JSON::decode_json($y[0]);
        my $len = @{$mes-&gt;{"servers"}};
        my %server_to_netaddr_hash;
        my %test;
        my $servername;
        my $state;
        my $status;
        my $test;
        my $vmcount=0;

	$status = $mes-&gt;{"servers"}[$x]{"OS-EXT-STS:vm_state"};
          $state = $mes-&gt;{"servers"}[$x]{"OS-EXT-STS:power_state"};
          if ( $status ne "active" || $state != 1) {
        print ("\n\n *******  status/state  of the vm $test is not correct.The current  status is $status and state is $state ******* \n\n");
         return JT::FALSE;
                        }
        print ("\n\n *******  status and state  of the vm $test is correct The current status is $status and state is $state******* \n\n");

                     }

root@ server1:~# nova list
+--------------------------------------+--------+--------+------------+-------------+--------------------+
| ID                                   | Name   | Status | Task State | Power State | Networks           |
+--------------------------------------+--------+--------+------------+-------------+--------------------+
| 935bb371-9fb6-4d1e-92b6-239db2d28a2a | nvmg1  | ACTIVE | -          | Running     | net1=100.0.4.252   |
| 69b9dca5-a4e0-4168-8363-b87caa65e741 | nvmg10 | ACTIVE | -          | Running     | net10=100.0.13.252 |
| 176f9b62-1561-41e9-9c2f-de86f76afffd | nvmg11 | ACTIVE | -          | Running     | net11=100.0.14.252 |
| 15eff465-7251-4de8-b371-cc85790ca9a6 | nvmg12 | ACTIVE | -          | Running     | net12=100.0.15.252 |
| c1be1e20-4969-4911-8fdf-81e09c0023e9 | nvmg13 | ACTIVE | -          | Running     | net13=100.0.16.252 |
| 449becae-69b7-4f57-947a-74d78875ef39 | nvmg2  | ACTIVE | -          | Running     | net2=100.0.5.252   |
| db8c1d5b-5990-458f-bfcb-13a7d2bdbbda | nvmg3  | ACTIVE | -          | Running     | net3=100.0.6.252   |
| a7ceee7e-539a-4398-a768-209db065a71c | nvmg4  | ACTIVE | -          | Running     | net4=100.0.7.252   |
| 43713c5b-c262-4e56-9a77-ffde968f448e | nvmg5  | ACTIVE | -          | Running     | net5=100.0.8.252   |
| 8010f8a0-56d8-4904-a747-8e5dfa1f8ac8 | nvmg6  | ACTIVE | -          | Running     | net6=100.0.9.252   |
| 0c57cb78-922b-4f76-98d5-f962f08a85a6 | nvmg7  | ACTIVE | -          | Running     | net7=100.0.10.252  |
| 47ca6427-c898-4d71-9c2d-61ffa533e31e | nvmg8  | ACTIVE | -          | Running     | net8=100.0.11.252  |
| a08bbaac-3ed9-4cf6-ad6c-def7484a35e4 | nvmg9  | ACTIVE | -          | Running     | net9=100.0.12.252  |
+--------------------------------------+--------+--------+------------+-------------+--------------------+
</span></pre>
<p>The status of the VMs can also be checked in OPENSTACK horizon GUI as shown below.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2017/01/Automating_Contrail_Cloud_Platform_Image3.jpg"><img decoding="async" class="alignnone wp-image-7282" src="http://www.opencontrail.org/wp-content/uploads/2017/01/Automating_Contrail_Cloud_Platform_Image3.jpg" width="1059" height="600" data-id="7282" /></a></p>
<p><strong>VM Deletion:</strong></p>
<p>Before start deleting the VMs we need to get the token-id from the Openstack server using the procedure given earlier.In addition to this we need to know the VM id.To get the VM id we can use the RESTAPI &#8220;/v2/&#8221;.$tenant_id.&#8221;/servers?name=&#8221;.$del_vm_name as shown below.</p>
<pre><span style="font-family: 'courier new', courier;">my $headers = "{ 'Content-Type' : 'application/json', 'Accept'  :  'application/json' , 'ser-Agent'  : 'python-novaclient', 'X-Auth-Token'   :    $token_id}";
        $CMDpath= "/v2/".$tenant_id."/servers?name=".$del_vm_name;
        $APIport=$NOVAport;
        $url= "http://".$cont_ip.":".$APIport.$CMDpath;
        $request  = HTTP::Request-&gt;new( GET =&gt; $url );
        $request-&gt;header('content-type' =&gt; 'application/json');
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);
        @y = $http-&gt;{_content};
        $mes         = JSON::decode_json($y[0]);
        #print "\n\n\n\n\n\---------------\n\n\n\n";
        #print Dumper($mes);
        my $del_vm_id = $mes-&gt;{'servers'}[0]{'id'};
        print ( "\n\n *******  delte vm instance id is $del_vm_id ******* \n\n");</span></pre>
<p>After getting the VM ID we can use the RESTAPI &#8220;/v1.1/&#8221;.$tenant_id.&#8221;/servers/&#8221;.$del_vm_id.&#8221;/action&#8221; to delete the VM.This is equivlant to “nova delete &lt;vm name/vm id&gt;” command.</p>
<pre><span style="font-family: 'courier new', courier;">$headers = "{ 'Content-Type' : 'application/json', 'Accept'  :  'application/json' , 'ser-Agent'  : 'python-novaclient', 'X-Auth-Token'   :    $token_id}";
        $CMDpath = "/v1.1/".$tenant_id."/servers/".$del_vm_id."/action";
        $APIport=$NOVAport;
        $url= "http://".$cont_ip.":".$APIport.$CMDpath;
        $body =
        {
               "forceDelete"   =&gt;  "null"
        };
        $request  = HTTP::Request-&gt;new( POST =&gt; $url );
        $bjson = encode_json $body;
        $request-&gt;content_type("application/json");
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $request-&gt;content($bjson);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);</span></pre>
<h3>Conclusion</h3>
<p>This document gives details on CONTRAIL cloud solution implementation. It also explains the RESTAPI details for  VM creation,VM deletion etc..</p>
<h3>APPENDIX</h3>
<p>The section give details on other RESTAPI commands.</p>
<h4>Deleting virtual network:</h4>
<p>This command is executed on the contrail controller. To run this command we need virtual network id.</p>
<pre><span style="font-family: 'courier new', courier;">$CMDpath = "/virtual-network/";
        $APIport="8082";
        $url= "http://".$cont_ip.":".$APIport.$CMDpath.$netid;
        $request  = HTTP::Request-&gt;new( DELETE =&gt; $url );
       $request-&gt;header('content-type' =&gt; 'application/json');
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);</span></pre>
<p>To get the virtual network id this RESTAPI is used.The “uuid” returns the network id.</p>
<pre><span style="font-family: 'courier new', courier;">$CMDpath = "/virtual-networks";
        $APIport="8082";
        $url= "http://".$cont_ip.":".$APIport.$CMDpath;
        $request  = HTTP::Request-&gt;new( GET =&gt; $url );
        $request-&gt;content_type("application/json");
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);
         print Dumper $http;
          @y = $http-&gt;{_content};
        $mes         = JSON::decode_json($y[0]);
          $len = @{$mes-&gt;{"virtual-networks"}};
        my @network_list;
        my $i=1;
        for (my $x = 0; $x&lt; $len ; ++$x) { if ($mes-&gt;{"virtual-networks"}[$x]{"fq_name"}[2]  =~ /net\d+/) {
                push (@network_list, $mes-&gt;{"virtual-networks"}[$x]{"uuid"});
                $i++;
            }
          }</span></pre>
<p>To delete the ports which map virtual network with the VM we need to use the RESTAPI given below.</p>
<p>We need portid to run this command.</p>
<pre><span style="font-family: 'courier new', courier;">My $NEUTRONport      =  "9696";
         $CMDpath = "/v2.0/ports/";
        $APIport=$NEUTRONport;
        $url= "http://".$cont_ip.":".$APIport.$CMDpath.$portid.".json";
        $request  = HTTP::Request-&gt;new( DELETE =&gt; $url );
       $request-&gt;header('content-type' =&gt; 'application/json');
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);</span></pre>
<p>The port id can be found from,</p>
<pre><span style="font-family: 'courier new', courier;">$CMDpath= "/v2.0/ports.json";
        $APIport=$NEUTRONport;
        $url= "http://".$cont_ip.":".$APIport.$CMDpath;
        $request  = HTTP::Request-&gt;new( GET =&gt; $url );
        $request-&gt;header('content-type' =&gt; 'application/json');
        $request-&gt;header('x-auth-token' =&gt; $token_id);
        $http = LWP::UserAgent-&gt;new-&gt;request($request);
        @y = $http-&gt;{_content};
        $mes         = JSON::decode_json($y[0]);
        my $len = @{$mes-&gt;{"ports"}};
        my @port_list;
        for (my $x = 0; $x&lt; $len ; ++$x) { push (@port_list, $mes-&gt;{"ports"}[$x]{"id"});
        }</span></pre>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Contrail Cloud Solution With MPLS-Over-UDP Overlays</title>
		<link>https://tungsten.io/contrail-cloud-solution-with-mpls-over-udp-overlays/</link>
		
		<dc:creator><![CDATA[Ramanathan Sethuraman]]></dc:creator>
		<pubDate>Wed, 04 Jan 2017 21:40:57 +0000</pubDate>
				<category><![CDATA[Automation]]></category>
		<category><![CDATA[MPLSoverGRE]]></category>
		<category><![CDATA[MPLSoverUDP]]></category>
		<category><![CDATA[Network Services]]></category>
		<category><![CDATA[Overlay Tunnels]]></category>
		<guid isPermaLink="false">http://www.opencontrail.org/?p=7265</guid>

					<description><![CDATA[Summary: MPLS-OVER-UDP Tunnels are used on datacenter environment as overlays. Existing technologies (like MPLS-OVER-GRE) to encapsulate Multi-Protocol Label Switching(MPLS) over IP are not adequate for efficient load balancing of MPLS...]]></description>
										<content:encoded><![CDATA[<h3><strong>Summary:</strong></h3>
<p>MPLS-OVER-UDP Tunnels are used on datacenter environment as overlays. Existing technologies (like MPLS-OVER-GRE) to encapsulate Multi-Protocol Label Switching(MPLS) over IP are not adequate for efficient load balancing of MPLS application traffic, such as Layer3 Virtual Private Network (L3VPN) traffic across IP networks. This document specifies IP-based encapsulation technology, referred to as MPLS-in-User Datagram Protocol (UDP), which can facilitate the load balancing of MPLS application traffic across IP networks. This document also gives details on how to enable MPLS-OVER-UDP encapsulation when MX router interop with contrail controller.</p>
<h3><strong>Description:</strong></h3>
<p>Figure 1 shows the frame formats of MPLS-OVER-GRE and MPLS-OVER-UDP.There no easy way to load share the traffic between 2 tunnel end points when MPLS-OVER-GRE encapsulation is used.The issue is GRE header is same for all the flows between the 2 Tunnel end points.</p>
<p>But when we use MPLS-OVER-UDP encapsulation the source port value(in the MPLS-OVER-UDP header) can be generated based on the certain fields in the customer packets(in our case based on the packets generated by VMs in the vRouter).With this the routers between the Tunnel end points can load share the packets using hash of five-tuple of UDP packets.This is one of reason why MPLS-OVER-UDP overlays preferred over MPLS-OVER-GRE overlays.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2017/01/IP-over-MPLS-over-UDP-Packet-Format.png"><img loading="lazy" decoding="async" class="alignnone size-full wp-image-7274" src="http://www.opencontrail.org/wp-content/uploads/2017/01/IP-over-MPLS-over-UDP-Packet-Format.png" alt="" width="450" height="138" /></a></p>
<p><strong>Figure 1</strong>: IP over MPLS over UDP Packet Format</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2017/01/IP-over-MPLS-over-UDP-Packet-Format_2.png"><img loading="lazy" decoding="async" class="alignnone size-full wp-image-7275" src="http://www.opencontrail.org/wp-content/uploads/2017/01/IP-over-MPLS-over-UDP-Packet-Format_2.png" alt="" width="443" height="135" /></a></p>
<p><strong>Figure 2</strong>: IP over MPLS over GRE Packet Format</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2017/01/MPLS-over-UDP-Overlay-Tunnels.jpg"><img loading="lazy" decoding="async" class="alignnone size-full wp-image-7277" src="http://www.opencontrail.org/wp-content/uploads/2017/01/MPLS-over-UDP-Overlay-Tunnels.jpg" alt="" width="696" height="492" /></a></p>
<p>The picture given above shows the implementation of Contrail cloud solution. In this topology PE2 &amp; PE3 will be acting as local Datacenter gateways.PE1 will be the remote Datacenter gateway.Between PE2/PE3 and compute nodes (or vRouters) MPLS-OVER-UDP overlays will be implemented.So all traffic between compute nodes to PE2/PE3 will be encapsulated with MPLS-OVER-UDP header.Contrail controllers will be managing the vRouters using XMPP.PE2 &amp;PE3 will talk to Contrail controllers with BGP.The vRouters in contrail cloud will act similar to PE router in L3 VPN environment.When vRouter need to send traffic to vRouters in another datacenter it will encapulate packets with MPLS-OVER-UDP header and forward it to PE2 or PE3.PE2 or PE3 will decapsulate the MPLS-OVER-UDP header and then encapsulate it with MPLS headers and forward it to PE1.PE1 decapsulate MPLS header and forward the packets to the node in remote Datacenter.</p>
<p>When a VM in a vRouter need to send traffic to VM in another vRouter in the same datacenter, the source vRouter will encapsulate the packets with MPLS-OVER-UDP/MPLS-OVER-GRE header and then forward it to the IP fabric.After the destination vRouter receives the packet it will decapsulate the packets and forward it to the destination VM.</p>
<h3>Configuration on MX gateway:</h3>
<p><strong>BGP Configuration :</strong></p>
<p><strong>BGP group contrail:</strong></p>
<p>This section gives details on BGP configuration of PE2 &amp; PE3.Both the PEs will have a similar configuration. BGP group “contrail” (given below) peers to contrail controller. In this configuration, Family route-target knob controls the advertisement of routes from PE2 &amp; PE3 to contrail controller.It makes sure that PE2 &amp; PE3 advertise only required routes based on the route-targets received from the contrail controller.</p>
<p>Contrail controller advertises the route targets(which is applied to the virtual Networks created in contrail controller) to PE2 &amp; PE3.PE2 &amp; PE3 advertise routes with matching route targets. Unmatched routes will not be advertised. This avoids unnecessary routes advertised to contrail controller. The knob external-paths 5 is required when you have 3 controllers in a HA environment.</p>
<p>Before advertising any routes to contrail controller the next-hop of the route (through policy from-remote-pe-vrf1) is changed to PE2 or PE3 loopback address.This avoids the need for the controller to learn remote PE1 loopback address.</p>
<p>This policy also adds encapsulation extended community to the remote datacenter route before advertising it to the contrail controller.This community tells the vRouter(compute nodes) to use MPLS-OVER-UDP encapsulation before it forwards traffic for this route.If this community is not advertised,  then vRouter will use the default encapsulation (which is MPLS-OVER-GRE).</p>
<p>The encapsulation community  is in the format of &#8220;members 0x030c:XXX:13&#8221;. This identifies it as opaque extended community (type 0x03) of sub-type encapsulation (0x0c).Administrator field is set to 0 since it&#8217;s reserved(But JUNOS do not allow 0 so you need to set it to some value recommended is AS NUMBER) and encap value is 13 (for MPLSoUDP).</p>
<p>The configuration given below is used in PE2 and PE3 routers.</p>
<pre><span style="font-family: 'courier new', courier">
{master}[edit]
regress@PE2# show protocols bgp group contrail     
type internal;
local-address 10.255.181.172;
family inet-vpn {
    any;
}
family inet6-vpn {
    any;
}
family route-target {
    external-paths 5;
    advertise-default;
}
export from-remote-pe-vrf1;
vpn-apply-export;
cluster 2.2.2.2;
neighbor 3.3.3.2;

{master}[edit]
regress@PE2# 

master}[edit]
regress@PE2# show policy-options policy-statement from-remote-pe-vrf1
term 1 {
    from {
          protocol bgp;
          route-filter 103.0.4.0/24 orlonger;
             }
    then {
        next-hop self;
        community add udp;
        accept;
    }
}

{master}[edit]
regress@PE2# show policy-options community udp         
members 0x030c:64512:13;

{master}[edit]
regress@PE2# </span></pre>
<p>You can verify encapsulation status in vRouter(in compute node) as shown below.For this first find the tap interface.Then check the route using the vrf number.This output shows the type of encapsulation, source and destination IPs of the tunnel and other details.</p>
<pre><span style="font-family: 'courier new', courier">root@vm6:~# vif --list
Vrouter Interface Table

Flags: P=Policy, X=Cross Connect, S=Service Chain, Mr=Receive Mirror
       Mt=Transmit Mirror, Tc=Transmit Checksum Offload, L3=Layer 3, L2=Layer 2
       D=DHCP, Vp=Vhost Physical, Pr=Promiscuous, Vnt=Native Vlan Tagged
       Mnp=No MAC Proxy, Dpdk=DPDK PMD Interface, Rfl=Receive Filtering Offload, Mon=Interface is Monitored
       Uuf=Unknown Unicast Flood, Vof=VLAN insert/strip offload

vif0/3      OS: tap6b9bb806-20
            Type:Virtual HWaddr:00:00:5e:00:01:00 IPaddr:0
            Vrf:1 Flags:PL3L2D MTU:9160 Ref:5
            RX packets:15533540  bytes:4717521394 errors:0
            TX packets:15659512  bytes:4721801850 errors:0


root@vm6:~# rt --dump 1 |grep 103.0.8.0/24
103.0.8.0/24           24            P          -             24        -
root@vm6:~# nh --get 24
Id:24         Type:Composite      Fmly: AF_INET  Rid:0  Ref_cnt:6          Vrf:1
              Flags:Valid, Policy, Ecmp, 
              Sub NH(label): 16(17) 12(17)


Id:12         Type:Tunnel         Fmly: AF_INET  Rid:0  Ref_cnt:2          Vrf:0
              Flags:Valid, MPLSoUDP, 
              Oif:0 Len:14 Flags Valid, MPLSoUDP,  Data:02 00 08 00 00 2b 52 54 00 23 13 39 08 00 
              Vrf:0  Sip:60.60.0.6  Dip:10.255.181.172

root@vm6:~# </span></pre>
<p>The picture given below shows the bgp configuration in Contrail controller.There are 2 nodes shown here.Router Type “BGP Router” shows the PE1 configuration details and Router Type “Control Node” details BGP configuration of Contrail Controller.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2017/01/BGP-Configuraton-in-Contrail-Controller.jpg"><img loading="lazy" decoding="async" class="alignnone wp-image-7266" src="http://www.opencontrail.org/wp-content/uploads/2017/01/BGP-Configuraton-in-Contrail-Controller.jpg" width="1148" height="600" /></a></p>
<p>&nbsp;</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2017/01/BGP-Configuraton-in-Contrail-Controller_2.jpg"><img loading="lazy" decoding="async" class="alignnone wp-image-7267" src="http://www.opencontrail.org/wp-content/uploads/2017/01/BGP-Configuraton-in-Contrail-Controller_2.jpg" width="1137" height="600" /></a></p>
<p>&nbsp;</p>
<p>The output from MX router (given below) shows that bgp connection established between MX and Contrail Controller.</p>
<p>&nbsp;</p>
<pre><span style="font-family: 'courier new', courier">{master}[edit]
regress@PE2# run show bgp summary 
Groups: 4 Peers: 5 Down peers: 0
Table          Tot Paths  Act Paths Suppressed    History Damp State    Pending
bgp.rtarget.0        
                      17         13          0          0          0          0
bgp.l3vpn.0          
                      58         54          0          0          0          0
bgp.l3vpn.2          
                       0          0          0          0          0          0
bgp.l3vpn-inet6.0    
                       0          0          0          0          0          0
bgp.l3vpn-inet6.2    
                       0          0          0          0          0          0
Peer                     AS      InPkt     OutPkt    OutQ   Flaps Last Up/Dwn State|#Active/Received/Accepted/Damped...
3.3.3.2               64512         40         56       0       0       11:15 Establ
  bgp.rtarget.0: 13/17/17/0
  bgp.l3vpn.0: 4/4/4/0
  bgp.l3vpn-inet6.0: 0/0/0/0
  vrf1.inet.0: 4/4/4/0</span></pre>
<h4>BGP Group core:</h4>
<p>This BGP Group “core” peers to the remote PE(PE1) connected to remote data center. The policy “change-next” will change the next hop off routes advertised to remote PE1.</p>
<p>&nbsp;</p>
<pre><span style="font-family: 'courier new', courier">{master}[edit] 
regress@PE2# show protocols bgp group core 
type internal;
local-address 10.255.181.172;
family inet-vpn {
    any;
}
family inet6-vpn {
    any;
}
export change-next;
vpn-apply-export;
neighbor 10.255.178.174;

{master}[edit]
regress@PE2# 


{master}[edit]
regress@PE2# show policy-options policy-statement change-next 
Dec 07 14:27:33
term 1 {
    from protocol bgp;
  then {
        next-hop self;
        accept;
    }
}

{master}[edit]
regress@PE2#</span></pre>
<h3>Dynamic tunnel configuration:</h3>
<p>This section explains Dynamic Tunnel Configuration between MX to Contrail Controller and MX to vrouter.</p>
<h4>Dynamic Tunnel to contrail controller:</h4>
<p>PE2 &amp; PE3 needs to have dynamic tunnel (MPLS-OVER-UDP/MPLS-OVER-GRE) created to the contrail controller. This configuration will create route to the controller ip address in inet.3 table.Without this route MX will not advertise bgp.l3vpn.0 table routes to controller(when you have family route-target enabled on PE2 &amp; PE3).This Tunnel status can be verified as shown below.This tunnel will be in Dn state as there are no routes received from controller with protocol next-hop of contrail controller IP address(in this case it is 3.3.3.2).This is expected as contrail controller will not be advertising any route with 3.3.3.2 as protocol next hop.</p>
<p>&nbsp;</p>
<pre><span style="font-family: 'courier new', courier">{master}[edit]
regress@PE2# show routing-options dynamic-tunnels to-controller       
source-address 10.255.181.172;
udp;
destination-networks {
    3.3.3.0/24;
}

{master}[edit]
regress@PE2# 


{master}[edit]
regress@PE2# run show dynamic-tunnels database terse 
Table: inet.3

Destination-network: 3.3.3.2/32
Destination         Source          Next-hop                  Type        Status
3.3.3.2/32          10.255.181.172  0x487e67c nhid 0          udp         Dn    nexthop not installed

master}[edit]
regress@PE2# run show route 3.3.3.0
Dec 07 13:53:43 

inet.0: 43 destinations, 44 routes (42 active, 0 holddown, 1 hidden)
+ = Active Route, - = Last Active, * = Both

3.3.3.0/24         *[OSPF/150] 00:40:14, metric 0, tag 0
                    &gt; to 1.0.1.1 via ae0.0

inet.3: 18 destinations, 31 routes (18 active, 0 holddown, 0 hidden)
+ = Active Route, - = Last Active, * = Both

3.3.3.0/24         *[Tunnel/300] 00:37:18
                      Tunnel

{master}[edit]
regress@PE2# </span></pre>
<h3>Dynamic Tunnels to vRouters:</h3>
<p>PE2 &amp; PE3 should create Dynamic TUNNELS to all the vROUTERs. In our case it is MPLS-OVER-UDP TUNNEL created between PE2 &amp; PE3 to all vROUTERs.When PE2 or PE3 receives traffic from remote PE1 it uses this MPLS-OVER-UDP tunnel to forward the traffic to the respective vROUTER.The Tunnel status can be verified as given below.The Tunnel will come up only when a route received with the protocol nexthop in the segment 60.60.0.0/16(which is configured in destination-networks as shown below).In this case 60.60.0.0/16 is the IP segment used vrouters.</p>
<p>&nbsp;</p>
<pre><span style="font-family: 'courier new', courier">regress@PE2# show routing-options dynamic-tunnels 
contrail-udp {
    source-address 10.255.181.172;
    udp;
    destination-networks {
       60.60.0.0/16;
    }
}
{master}[edit]
regress@PE2# run show dynamic-tunnels database 
Table: inet.3
Destination-network: 60.60.0.6/32
Tunnel to: 60.60.0.6/32
  Reference count: 1
  Next-hop type: UDP
    Source address: 10.255.181.172 Tunnel Id: 1610612742
    Next hop: tunnel-composite, 0x4875634, nhid 710
      Reference count: 2
      State: Up


{master}[edit]
regress@PE2# run show dynamic-tunnels database terse 
Table: inet.3

Destination-network: 60.60.0.6/32
Destination         Source          Next-hop                  Type        Status
60.60.0.6/32        10.255.181.172  0x48793f4 nhid 741        udp         Up   </span></pre>
<p>&nbsp;</p>
<p>This is the Routing instance configuration is created on PE2 &amp; PE3 to install the routes to vrf table.This vrf configuration is required as it is a L3VPN scenario.</p>
<p>&nbsp;</p>
<pre><span style="font-family: 'courier new', courier">{master}[edit]
regress@PE2# show routing-instances vrf1 
instance-type vrf;
interface lo0.1;
route-distinguisher 64512:1;
vrf-import test1-import;
vrf-export test1-export;
vrf-table-label;
}

{master}[edit]
regress@PE2# show policy-options policy-statement test1-export
term 1 {
    from protocol  direct ;
    then {
        community add testtarget1;
        accept;
    }
}

{master}[edit]
regress@PE2# 

regress@PE2# show policy-options policy-statement test1-import 
term 1 {
    from community testtarget1;
    then accept;
}

{master}[edit]
regress@PE2#</span></pre>
<h3>Remote datacenter PE configuration:</h3>
<p>This configuration is applied on the remote PE router (in this case PE1).This is a simple L3VPN configuration.</p>
<pre><span style="font-family: 'courier new', courier">[edit]
regress@PE1# show routing-instances vrfs1 
Dec 06 13:21:03
instance-type vrf;
interface xe-1/1/1.1;
interface xe-1/1/1.2;
interface xe-1/1/1.3;
interface xe-1/1/1.4;
route-distinguisher 64512:1;
vrf-import test1-import;
vrf-export test1-export;
vrf-table-label;

[edit]
regress@PE1# show policy-options policy-statement test1-export 
Dec 06 13:21:10
term 1 {
    from protocol direct;
    then {
        community add testtarget1;
        accept;
    }
}

[edit]
regress@PE1# show policy-options policy-statement test1-import    
term 1 {
    from community testtarget1;
    then accept;
}

[edit]
regress@PE1# 

[edit]
regress@PE1# show protocols bgp
precision-timers;
group contrail-1 {
    type internal;
    local-address 10.255.178.174;
    family inet {
        unicast;
    }
    family inet-vpn {
        any;
    }
    family inet6-vpn {
        any;
    }
    cluster 3.3.3.3;
    neighbor 10.255.181.172;
        
[edit]
regress@PE1# </span></pre>
<h3>Conclusion</h3>
<p>In this document we have shown the use case of MPLS-OVER-UDP overlays. In addition to this configuration required to integrate MPLS-OVER-UDP overlays between MX and contrail controller is explained in this document.</p>
<h3>APPENDIX A</h3>
<p>The tunnel details from the FPC can be checked as shown below.The nexthop id can be used to check the tunnel details from the FPC.The Tunnel id,tunnel destination,Tunnel source in the FPC should match with the CLI.</p>
<p>&nbsp;</p>
<pre><span style="font-family: 'courier new', courier">{master}[edit]
regress@PE2# run show dynamic-tunnels database 
Dec 06 14:06:45
Table: inet.3

Destination-network: 60.60.0.6/32
Tunnel to: 60.60.0.6/32
  Reference count: 1
  Next-hop type: UDP
    Source address: 10.255.181.172 Tunnel Id: 1610612742
    Next hop: tunnel-composite, 0x4875634, nhid 710
      Reference count: 2
      State: Up

regress@PE2# run request pfe execute target fpc3 command "show nhdb id 710 extensive"       
Dec 07 13:58:26 
================ fpc3 ================
SENT: Ukern command: show nhdb id 710 extensive

   ID      Type      Interface    Next Hop Addr    Protocol       Encap     MTU               Flags  PFE internal Flags
-----  --------  -------------  ---------------  ----------  ------------  ----  ------------------  ------------------
  710    Compst  -              -                      MPLS             -     0  0x0000000000000000  0x0000000000000000

BFD Session Id: 0

Composite NH:
  Function: Tunnel Function
  Hardware Index: 0x0
  Composite flag: 0x0
  Composite pfe flag: 0xe
  Lower-level NH Ids:
  Derived NH Ids:
  Tunnel Data:
      Type     : UDP-V4
      Tunnel ID: 1610612742
      Encap VRF: 0
      Decap VRF: 0
      MTU      : 0
      Flags    : 0x2
      Encap Len: 28
      Encap    : 0x45 0x00 0x00 0x00 0x00 0x00 0x40 0x00
                 0x40 0x2f 0x00 0x00 0xac 0xb5 0xff 0x0a
                 0x06 0x00 0x3c 0x3c 0x00 0x00 0x00 0x00
                 0x00 0x00 0x00 0x00
      Data Len : 8
      Data     : 0x3c 0x3c 0x00 0x06 0x0a 0xff 0xb5 0xac
        Feature List: NH
           [pfe-0]: 0x08ce6d4c00100000;
           [pfe-1]: 0x08c12e3000100000;
          f_mask:0xe000000000000000; c_mask:0xe000000000000000; f_num:3; c_num:3,  inst:0xffffffff
        Idx#0          -:               
           [pfe-0]: 0x2bfffffd5e00a500  
           [pfe-1]: 0x2bfffffd5e00a500  
                                        
        Idx#1          -:               
           [pfe-0]: 0x23fffffc0000000c  
           [pfe-1]: 0x23fffffc0000000c  
                                        
        Idx#2          -:               
           [pfe-0]: 0x08c045d800080000  
           [pfe-1]: 0x08c03d8800080000  
                                        
Tunnel ID 1610612742                    
==============                          
         Ref-count 1                    
TunnelModel:                            
Dynamic Tunnel Model:                   
         Name = MPLSoUDP                
         MTU = 0                        
         VRF = default.0(0)             
         Source Entropy = 1             
         Packets = 0 Bytes = 0          
                                        
Source IP     : 10.255.181.172          
Destination IP: 60.60.0.6     


Ingress:                                
Index:0                                 
  PFE(0): 0x2bfffffd5e006500            
  PFE(1): 0x2bfffffd5e006500            
                                        
Index:1                                 
  PFE(0): 0x8ce6c8c00100000             
  PFE(1): 0x8c12d7000100000             
                                        
Handle JNH
0x8c045d800080000
0x8c03d8800080000
Egress:
Index:0
  PFE(0): 0x2bfffffd5e008500
  PFE(1): 0x2bfffffd5e008500

Index:1
  PFE(0): 0x23fffffc0000020a
  PFE(1): 0x23fffffc0000020a

Index:2
  PFE(0): 0x878b15400100000
  PFE(1): 0x878b2b000100000

Handle JNH
0x8ce6cec00100000
0x8c12dd000100000


  Routing-table id: 0</span></pre>
<h3>Full configuration:</h3>
<h4>PE2:</h4>
<p>&nbsp;</p>
<pre><span style="font-family: 'courier new', courier">{master}[edit]
regress@PE2# show protocols ospf
area 0.0.0.0 {
    interface all {
        bfd-liveness-detection {
            minimum-interval 300;
            multiplier 3;
        }
    }
    interface fxp0.0 {
        disable;
    }
}

{master}[edit]
regress@PE2# 

regress@PE2# show protocols mpls
ipv6-tunneling;
interface all;
{master}[edit]
regress@PE2# 

egress@PE2# show protocols ldp;
interface ae0.0;
interface ae1.0;
interface ae2.0;
interface lo0.0;
{master}[edit]
regress@PE2#
 
{master}[edit]
regress@PE2# show protocols bgp group contrail   
type internal;
local-address 10.255.181.172;
family inet-vpn {
    any;
}
family inet6-vpn {
    any;
}
family route-target {
 external-paths 5;
 advertise-default;
}
export from-remote-pe-vrf1;
cluster 2.2.2.2;
neighbor 3.3.3.2;
{master}[edit]
regress@PE2# 

{master}[edit]
regress@PE2# show protocols bgp group core        
type internal;
local-address 10.255.181.172;
family inet-vpn {
    any;
}
family inet6-vpn {
    any;
}
export change-next;
vpn-apply-export;
neighbor 10.255.178.174;
{master}[edit]
regress@PE2# 

regress@leopard# show routing-options              
Dec 13 12:19:18
ppm {
    redistribution-timer 120;
}
nonstop-routing;
autonomous-system 64512;
dynamic-tunnels {
    gre next-hop-based-tunnel;
    controller {
        source-address 10.255.181.172;
        udp;
        destination-networks {
            3.3.3.2/32;
        }
    }
contrail-udp {
        source-address 10.255.181.172;
        udp;
        destination-networks {
            60.60.0.0/16;
  }
}
}
regress@PE2# show policy-options policy-statement from-remote-pe-vrf1
term 1 {
    from {
          protocol bgp;
          route-filter 103.0.4.0/24 orlonger;
             }
    then {
        next-hop self;
        accept;
    }
}

{master}[edit]
regress@PE2# show policy-options community udp         
members 0x030c:64512:13;

{master}[edit]
regress@PE2# 
{master}[edit]
regress@PE2# show policy-options policy-statement change-next 
Dec 07 14:27:33
term 1 {
    from protocol bgp;
  then {
        next-hop self;
        accept;
    }
}

{master}[edit]
regress@PE2#</span></pre>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>@ContrailBot &#8211; Bot as a Service (BaaS)</title>
		<link>https://tungsten.io/contrailbot-bot-as-a-service-baas/</link>
		
		<dc:creator><![CDATA[Savithru Lokanath]]></dc:creator>
		<pubDate>Mon, 24 Oct 2016 14:02:46 +0000</pubDate>
				<category><![CDATA[Automation]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.opencontrail.org/?p=7224</guid>

					<description><![CDATA[As computers become smarter, many new technologies have emerged. One technology which has taken a significant leap in the past few years is Artificial Intelligence &#38; many new services have...]]></description>
										<content:encoded><![CDATA[<p><iframe loading="lazy" src="https://www.youtube.com/embed/06aEYYb4cMg" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe><br />
As computers become smarter, many new technologies have emerged. One technology which has taken a significant leap in the past few years is Artificial Intelligence &amp; many new services have been built around this.</p>
<p>In this blog, we’ll look at one such service which is getting attention off late, called ChatOps (Chat Operations). ChatOps constitute a <strong>“ChatBot”</strong> or simply <strong>“Bot”</strong>, which are asynchronous conversational interfaces that help users to interact with applications. There are many bots out there, which can help you book flight tickets, order food, etc. <em>“Bot as a Service (BaaS)”</em> &amp; <em>“Artificial-Intelligence as a Service (AIaaS)”</em> are the new buzzwords.</p>
<p>Taking it one step further, I introduce you to a bot which I call the <strong>“Contrail-Bot”</strong>. The bot interacts with the OpenContrail SDN controller &amp; has a complete overview of the cloud (OpenContrail + OpenStack) infrastructure. By interfacing with OpenContrail, the bot offers the cloud-admin an interactive tool to build &amp; manage the OpenStack infrastructure. The cloud-admin strikes a conversation by making requests to the <strong>Contrail-Bot</strong> &amp; the bot will in turn translate these requests into a language that the OpenContrail SDN controller understands (Python/REST/CLI). The response from the controller is translated back &amp; presented to the cloud-admin in a human readable format.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image1.png"><img loading="lazy" decoding="async" class="size-full wp-image-7225 alignnone" src="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image1.png" alt="contrail-chatbot-blog-image1" width="752" height="155" data-id="7225" /></a></p>
<p>I started developing the <strong>Contrail-Bot</strong> with a couple of objectives in mind,</p>
<ul>
<li>I should be able to know if my cloud-services are all healthy &amp; are running fine</li>
</ul>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image2.png"><img loading="lazy" decoding="async" class="alignnone size-full wp-image-7230" src="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image2.png" alt="contrail-chatbot-blog-image2" width="732" height="323" data-id="7230" /></a></p>
<ul>
<li>I should be able to execute all Linux commands on the target nodes (Power-User mode)</li>
</ul>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image3.png"><img loading="lazy" decoding="async" class="alignnone size-full wp-image-7226" src="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image3.png" alt="contrail-chatbot-blog-image3" width="1036" height="147" data-id="7226" /></a></p>
<ul>
<li>I should be able to reimage &amp; provision servers quickly with the OS &amp; build of my choice (Contrail-Server-Manager integration)</li>
</ul>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image4.png"><img loading="lazy" decoding="async" class="alignnone size-full wp-image-7227" src="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image4.png" alt="contrail-chatbot-blog-image4" width="1040" height="496" data-id="7227" /></a></p>
<ul>
<li>I should be able to monitor my cloud &amp; minimize downtime (Get real-time text/call alerts)</li>
</ul>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image5.png"><img loading="lazy" decoding="async" class="alignnone size-full wp-image-7228" src="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image5.png" alt="contrail-chatbot-blog-image5" width="1024" height="362" data-id="7228" /></a></p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image6.png"><img loading="lazy" decoding="async" class="alignnone size-full wp-image-7229" src="http://www.opencontrail.org/wp-content/uploads/2016/10/contrail-chatbot-blog-image6.png" alt="contrail-chatbot-blog-image6" width="447" height="390" data-id="7229" /></a></p>
<p>As the <strong>Contrail-Bot</strong> evolves, I plan to introduce AI, which will allow the bot to learn continuously from user requests &amp; take intelligent decisions (Eg. running diagnostic tests, healing the network, etc.) in the event of a failure.</p>
<p>Let the bot revolution begin!</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Multi DataCenter Interconnect using OpenContrail</title>
		<link>https://tungsten.io/multi-datacenter-interconnect-using-opencontrail/</link>
		
		<dc:creator><![CDATA[Ranjini Rajendran]]></dc:creator>
		<pubDate>Fri, 31 Jul 2015 02:14:04 +0000</pubDate>
				<category><![CDATA[Automation]]></category>
		<category><![CDATA[BGPaaS]]></category>
		<category><![CDATA[Gateway]]></category>
		<category><![CDATA[Network Services]]></category>
		<category><![CDATA[Routing/Switching]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.opencontrail.org/?p=6454</guid>

					<description><![CDATA[In typical Enterprise Data Center deployments, the data center would span across multiple sites and there would be a need to have workloads across these sites. This would boil down...]]></description>
										<content:encoded><![CDATA[<p>In typical Enterprise Data Center deployments, the data center would span across multiple sites and there would be a need to have workloads across these sites. This would boil down to extending virtual networks to these multiple sites and ability to launch workloads on any site and be able to communicate between these workloads seamlessly as if they are in the same cluster.</p>
<p>In OpenContrail, this is made possible by federating the controllers in the different sites of a Multi-site DC without the need of a physical gateway. The control nodes in each site are peered with other sites using BGP. With this it is possible to stretch both L2 and L3 networks across multiple DCs.</p>
<p>The physical topology in this case is as shown below:</p>
<p><img loading="lazy" decoding="async" class=" wp-image-6456 aligncenter" src="http://www.opencontrail.org/wp-content/uploads/2015/07/physical_topology_opencontrail_controller_federation_blogpost.png" alt="physical_topology_opencontrail_controller_federation_blogpost" width="700" height="166" data-id="6456" /></p>
<p>The two DCs in different locations are having two different AS numbers and their control nodes are federated using BGP. The virtual networks can span across these two DCs. Also the network policies and security groups can also work seamlessly across these two DCs.</p>
<p>The logical view of the system is shown below:</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/logical_view_opencontrail_controller_federation_blogpost.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6455" src="http://www.opencontrail.org/wp-content/uploads/2015/07/logical_view_opencontrail_controller_federation_blogpost.png" alt="logical_view_opencontrail_controller_federation_blogpost" width="700" height="247" data-id="6455" /></a></p>
<p>Logically, the virtual machines spawned in another DC in the same VN can talk to each other like VMs in the same DC. They don’t see any difference.</p>
<p>A demo video on how controller can be federated in OpenContrail is available here:</p>
[video_lightbox_youtube video_id=&#8221;HIslWml97Ps&#8221; width=&#8221;720&#8243; height=&#8221;540&#8243; auto_thumb=&#8221;1&#8243;]
<p>With this, we have shown that using controller federation in OpenContrail; we can seamlessly stretch virtual networks ( both Layer 3 and Layer 2), network policies and security groups across multiple remote data center locations.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>A journey of a packet within OpenContrail</title>
		<link>https://tungsten.io/a-journey-of-a-packet-within-opencontrail/</link>
		
		<dc:creator><![CDATA[Sylvain Afchain]]></dc:creator>
		<pubDate>Wed, 29 Jul 2015 20:40:58 +0000</pubDate>
				<category><![CDATA[Automation]]></category>
		<category><![CDATA[BGPaaS]]></category>
		<category><![CDATA[Gateway]]></category>
		<category><![CDATA[Network Services]]></category>
		<category><![CDATA[Routing/Switching]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.opencontrail.org/?p=6435</guid>

					<description><![CDATA[This is a guest blog by Sylvain Afchain from RedHat. Click here for the original post. In this post we will see how a packet generated by a VM is...]]></description>
										<content:encoded><![CDATA[<p><em>This is a guest blog by <span class="author vcard"><a class="url fn n" title="Sylvain Afchain" href="https://twitter.com/s_afchain" target="_blank" rel="author">Sylvain Afchain </a></span> from RedHat. <a href="http://techs.enovance.com/7640/a-journey-of-a-packet-within-opencontrail" target="_blank">Click here</a> for the original post.</em></p>
<p>In this post we will see how a packet generated by a VM is able to reach another VM or an external resource, what are the key concepts/components in the context of Neutron using the OpenContrail plugin. We will focus on OpenContrail, how it implements the overlay and the tools that it provides to check/troubleshoot how the packet are forwarded. Before getting started, I’ll give a little overview of the key concepts of OpenContrail.</p>
<h4>Virtual networks, Overlay with OpenContrail</h4>
<p>For the overlay, OpenContrail uses MPLS L3VPNs and MPLS EVPNs in order to address both l3 overlay and l2 overlay. There are a lot of components within OpenContrail, however we will focus on two key components – controller and the vRouter.</p>
<p>For the control plane each controller acts as a BGP Route Reflector using the BGP and the XMPP protocols. BGP is used between the controllers and the physical routers. XMPP is used between the controllers and the vRouters. The XMPP protocol transports BGP route announcements but also some other informations for non routing needs.</p>
<p>For the data plane, OpenContrail supports GRE/VXLAN/UDP for the tunneling. OpenContrail requires the following features to be supported by the gateway router :</p>
<ul>
<li>L3VPN
<ul>
<li><a href="http://tools.ietf.org/html/rfc4364">http://tools.ietf.org/html/rfc4364</a></li>
</ul>
</li>
<li>MP-BGP
<ul>
<li><a href="http://tools.ietf.org/html/rfc4760">http://tools.ietf.org/html/rfc4760</a></li>
</ul>
</li>
<li>Dynamic Tunneling</li>
</ul>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/safchain_blogpost_728_image1.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6436" src="http://www.opencontrail.org/wp-content/uploads/2015/07/safchain_blogpost_728_image1.png" alt="safchain_blogpost_728_image1" width="533" height="300" data-id="6436" /></a></p>
<p>In this post we will focus on the data plane area.</p>
<h2 id="3">The packet’s journey</h2>
<p>In order to show what is the journey of a packet, let’s play with the following topology, where we have two VMs on two different networks connected thanks to a router.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-6437" src="http://www.opencontrail.org/wp-content/uploads/2015/07/safchain_blogpost_728_image2.png" alt="safchain_blogpost_728_image2" width="564" height="552" data-id="6437" /></p>
<p>Assuming we have allowed the ICMP packets by setting the security groups accordingly we can start a ping from <i>vm1</i> toward <i>vm2</i>.</p>
<p>There are a lot of introspection tools within OpenContrail which can be used to get a clear status on how the packets are forwarded.</p>
<p>Initiating a ping between <i>vm1</i> and <i>vm2</i>, we can check step by step where the packets go.</p>
<p>Since the VMs are not on the same network, they will both use their default gateway. The local vRouter answers to the ARP request of the default gateway IP with its own MAC.</p>
<pre><span style="font-family: 'courier new', courier;">
vm1$ ip route
default via 10.0.0.1 dev eth0
10.0.0.0/24 dev eth0  src 10.0.0.3
 
$ cat /proc/net/arp
IP address       HW type     Flags       HW address            Mask     Device
10.0.0.1         0x1         0x2         00:00:5e:00:01:00     *        eth0</span></pre>
<p>Now that we have seen that the packets will be forwarded to the local vRouter, we are going to check how the vRouter will forward them.</p>
<p>So let’s start by checking at the data plane layer by browsing the vRouter agent introspect Web interface running on the compute nodes hosting our VMs at <i>http://&lt;vrouter agent ip&gt;:8085/agent.xml</i></p>
<p>There is a plenty of sub-interfaces, but we will only use three of them:</p>
<ul>
<li>VrfListReq, http://&lt;vrouter agent ip&gt;:8085/Snh_VrfListReqWhich gives you the networks and the VRFs related. For a given VRF – let’s say the Unicast VRF (ucindex) – we can see all the routes.</li>
</ul>
<ul>
<li>ItfReq, http://&lt;vrouter agent ip&gt;:8085/Snh_ItfReqWhich gives you all the interfaces handled by the vRouter.</li>
<li>MplsReq, http://&lt;vrouter agent ip&gt;:8085/Snh_MplsReqWhich gives all the association MPLS Label/NextHop for the given vRouter</li>
</ul>
<p>These interfaces are just XML document rendered thanks to a XSL stylesheet, so can be easily processed by some monitoring scripts for example.</p>
<p>We can start by the interfaces (ItfReq) introspect page to find the TAP interface corresponding to VM1. The name of the TAP contains a part of the neutron port ID.</p>
<p><img loading="lazy" decoding="async" class="aligncenter wp-image-6445" src="http://www.opencontrail.org/wp-content/uploads/2015/07/safchain_blogpost_728_image6.png" alt="safchain_blogpost_728_image6" width="739" height="300" data-id="6445" /></p>
<p>Beside the interface we see the VRF name associated to the network that the interface belong to. On the same line we have some others informations, security group, floating-ips, VM id, etc.</p>
<p>Clicking on the VRF link brings us to the index page of this VRF. We see that we have links to VRFs according to their type: Unicast, Multicast, Layer 2. By default, OpenContrail doesn’t handle the Layer 2. As said before most of the Layer 2 traffic from the virtual machines are trapped by the local vRouter which acts as an ARP responder. But some specific packets like broadcasts still need to be handled, that’s why there is a specific Layer 2 VRF.</p>
<p><img loading="lazy" decoding="async" class="aligncenter wp-image-6442 size-full" src="http://www.opencontrail.org/wp-content/uploads/2015/07/safchain_blogpost_728_image3.png" alt="safchain_blogpost_728_image3" width="688" height="241" data-id="6442" /></p>
<p>Clicking on the link in the <i>ucindex</i> (Unicast) column, we can see all the unicast L3 routes of our virtual network handled by this vRouter. Since <i>vm1</i> should be able to reach vm2, we should see a route with the IP of <i>vm2</i>.</p>
<p><img loading="lazy" decoding="async" class="aligncenter wp-image-6443" src="http://www.opencontrail.org/wp-content/uploads/2015/07/safchain_blogpost_728_image4.png" alt="safchain_blogpost_728_image4" width="842" height="400" data-id="6443" /></p>
<p>Thanks to this interface we see that in order to reach the IP 192.168.0.3 which is the IP of our <i>vm2</i>, the packet is going to be forwarded through a GRE tunnel whose endpoint is the IP of the compute node hosting <i>vm2</i>. That’s what we see in the “<i>dip</i>” (Destination IP) field. We see that the packet will be encapsulated in a MPLS packet. The MPLS label will be 16, as shown in the label column.</p>
<p>Ok, so we saw at the agent level how the packet is going to be forwarded, but we may want to check on the datapath side. OpenContrail provides command line tools for that purpose.</p>
<p>In the case of the agent for instance, we can see the interfaces handled by the vRouter kernel module and the associated VRF.</p>
<pre><span style="font-family: 'courier new', courier;">$ vif --list
Vrouter Interface Table
 
Flags: P=Policy, X=Cross Connect, S=Service Chain, Mr=Receive Mirror
      Mt=Transmit Mirror, Tc=Transmit Checksum Offload, L3=Layer 3, L2=Layer 2
      D=DHCP, Vp=Vhost Physical, Pr=Promiscuous, Vnt=Native Vlan Tagged
      Mnp=No MAC Proxy, Dpdk=DPDK PMD Interface, Rfl=Receive Filtering Offload, 
      Mon=Interface is Monitored, Uuf=Unknown Unicast Flood
 
vif0/0      OS: eth0
           Type:Physical HWaddr:fa:16:3e:68:f9:e8 IPaddr:0
           Vrf:0 Flags:TcL3L2Vp MTU:1514 Ref:5
           RX packets:1598309  bytes:315532297 errors:0
           TX packets:1407307  bytes:383580260 errors:0
 
vif0/1      OS: vhost0
           Type:Host HWaddr:fa:16:3e:68:f9:e8 IPaddr:a2b5b0a
           Vrf:0 Flags:L3L2 MTU:1514 Ref:3
           RX packets:1403461  bytes:383378275 errors:0
           TX packets:1595855  bytes:315456061 errors:0
 
vif0/2      OS: pkt0
           Type:Agent HWaddr:00:00:5e:00:01:00 IPaddr:0
           Vrf:65535 Flags:L3 MTU:1514 Ref:2
           RX packets:4389  bytes:400688 errors:0
           TX packets:6931  bytes:548756 errors:0
 
vif0/3      OS: tapa87ad91e-28
           Type:Virtual HWaddr:00:00:5e:00:01:00 IPaddr:0
           Vrf:1 Flags:PL3L2 MTU:9160 Ref:6
           RX packets:565  bytes:105481 errors:0
           TX packets:587  bytes:80083 errors:0
 
vif0/4350   OS: pkt3
           Type:Stats HWaddr:00:00:00:00:00:00 IPaddr:0
           Vrf:65535 Flags:L3L2 MTU:9136 Ref:1
           RX packets:3  bytes:294 errors:0
           TX packets:3  bytes:252 errors:0
 
vif0/4351   OS: pkt1
           Type:Stats HWaddr:00:00:00:00:00:00 IPaddr:0
           Vrf:65535 Flags:L3L2 MTU:9136 Ref:1
           RX packets:10  bytes:840 errors:0
           TX packets:10  bytes:840 errors:0</span></pre>
<p>We have our TAP interface at this index 3 and the VRF associated which is the number 1.</p>
<p>Let’s now check the routes for this VRF. For that purpose we use the rt command line.</p>
<pre><span style="font-family: 'courier new', courier;">$ rt --dump 1
Vrouter inet4 routing table 0/1/unicast
Flags: L=Label Valid, P=Proxy ARP, T=Trap ARP, F=Flood ARP
 
Destination          PPL        Flags        Label         Nexthop    Stitched MAC(Index)
 
...
192.168.0.3/32         32           LP         16             19        -
...</span></pre>
<p>We see that the MPLS label used is 16. In order to know how the packet will be forwarded we have to check the NextHop used for this route.</p>
<pre><span style="font-family: 'courier new', courier;">$ nh --get 19
Id:19         Type:Tunnel    Fmly: AF_INET  Flags:Valid, MPLSoGRE,   Rid:0  Ref_cnt:2 Vrf:0
             Oif:0 Len:14 Flags Valid, MPLSoGRE,  Data:fa 16 3e 4b f6 05 fa 16 3e 68 f9 e8 08 00
             Vrf:0  Sip:10.43.91.10  Dip:10.43.91.12</span></pre>
<p>We have almost the same informations that the agent gave us. Here in the Oif field, we have the interface where the packet will be sent to the other compute node. Thanks to the vif command line we can get the details about this interface.</p>
<pre><span style="font-family: 'courier new', courier;">$ vif --get 0
Vrouter Interface Table
 
Flags: P=Policy, X=Cross Connect, S=Service Chain, Mr=Receive Mirror
      Mt=Transmit Mirror, Tc=Transmit Checksum Offload, L3=Layer 3, L2=Layer 2
      D=DHCP, Vp=Vhost Physical, Pr=Promiscuous, Vnt=Native Vlan Tagged
      Mnp=No MAC Proxy, Dpdk=DPDK PMD Interface, Rfl=Receive Filtering Offload, Mon=Interface is Monitored
      Uuf=Unknown Unicast Flood
 
vif0/0      OS: eth0
           Type:Physical HWaddr:fa:16:3e:68:f9:e8 IPaddr:0
           Vrf:0 Flags:TcL3L2Vp MTU:1514 Ref:5
           RX packets:1602164  bytes:316196179 errors:0
           TX packets:1410642  bytes:384855228 errors:0</span></pre>
<p>As the packet will go through the eth0 interface, a tcpdump should confirm what we described above.</p>
<pre><span style="font-family: 'courier new', courier;">$ sudo tcpdump -n -i eth0 dst 10.43.91.12
12:13:16.908957 IP 10.43.91.10 &gt; 10.43.91.12: GREv0, 
length 92: MPLS (label 16, exp 0, [S], ttl 63) 
IP 10.0.0.3 &gt; 192.168.0.3: ICMP echo request, id 5889, seq 43, length 64</span></pre>
<p>As the tunnel endpoint shows, the packet will be directly forwarded to the compute node that is hosting the destination VM, not using a third party routing device.</p>
<p>On the other side, the vRouter on the second compute node will receive the encapsulated packet. According to the MPLS Label, it does a lookup on a MPLS Label/NextHop as we can see on its introspect.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-6444" src="http://www.opencontrail.org/wp-content/uploads/2015/07/safchain_blogpost_728_image5.png" alt="safchain_blogpost_728_image5" width="678" height="538" data-id="6444" /></p>
<p>As we can see here the NextHop field for the Label 16 is the TAP interface of our second VM. On the datapath side we can check the same informations. Checking the MPLS Label/NextHop table :</p>
<pre><span style="font-family: 'courier new', courier;">$ mpls --get 16
MPLS Input Label Map
 
  Label    NextHop
-------------------
     16        14</span></pre>
<p>..and finally the NextHop and the interface with the following commands :</p>
<pre><span style="font-family: 'courier new', courier;">$ nh --get 14
Id:14         Type:Encap     Fmly: AF_INET  Flags:Valid, Policy,   Rid:0  Ref_cnt:4 Vrf:1
             EncapFmly:0806 Oif:3 Len:14 Data:02 8a 39 ff 98 d3 00 00 5e 00 01 00 08 00

$ vif --get 3
Vrouter Interface Table
 
Flags: P=Policy, X=Cross Connect, S=Service Chain, Mr=Receive Mirror
      Mt=Transmit Mirror, Tc=Transmit Checksum Offload, L3=Layer 3, L2=Layer 2
      D=DHCP, Vp=Vhost Physical, Pr=Promiscuous, Vnt=Native Vlan Tagged
      Mnp=No MAC Proxy, Dpdk=DPDK PMD Interface, Rfl=Receive Filtering Offload, Mon=Interface is Monitored
      Uuf=Unknown Unicast Flood
 
vif0/3      OS: tap8a39ff98-d3
           Type:Virtual HWaddr:00:00:5e:00:01:00 IPaddr:0
           Vrf:1 Flags:PL3L2 MTU:9160 Ref:6
           RX packets:2957  bytes:293636 errors:0
           TX packets:3085  bytes:297115 errors:0</span></pre>
<p>This post was just an overview on how the packets are forwarded from one node to another and what are the interfaces/tools that you can use for troubleshooting purpose. One of the interesting thing with OpenContrail is that almost all the components have their own introspect interface helping you a lot during troubleshooting sessions. As we saw, the routing is fully distributed in OpenContrail, each vRouter handles a part of the routing using well known routing protocols like BGP/MPLS which proved their ability to scale.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>OpenContrail SDN Lab testing 1 &#8211; ToR Switches with OVSDB</title>
		<link>https://tungsten.io/opencontrail-sdn-lab-testing-1-tor-switches-with-ovsdb/</link>
		
		<dc:creator><![CDATA[Jakub Pavlik]]></dc:creator>
		<pubDate>Tue, 14 Jul 2015 00:03:02 +0000</pubDate>
				<category><![CDATA[Automation]]></category>
		<category><![CDATA[BGPaaS]]></category>
		<category><![CDATA[Gateway]]></category>
		<category><![CDATA[Network Services]]></category>
		<category><![CDATA[Routing/Switching]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.opencontrail.org/?p=6368</guid>

					<description><![CDATA[This is a guest blog from tcpCloud authored by Marek Celoud &#38; Jakub Pavlik (tcp cloud engineers) along with Rostislav Safar (Arrow ECS network engineer). To see the original post,...]]></description>
										<content:encoded><![CDATA[<p>This is a guest blog from tcpCloud authored by Marek Celoud &amp; Jakub Pavlik (tcp cloud engineers) along with Rostislav Safar (Arrow ECS network engineer). To see the original post, <a href="http://tcpcloud.eu/en/blog/2015/07/13/opencontrail-sdn-lab-testing-1-tor-switches-ovsdb/">click here</a>.</p>
<p>Nobody doubts that OpenStack is the best open source project for private and public clouds today. OpenStack has begun to be perceived as a standard platform not only for laboratory or development environments, but has became suitable for large enterprises and service providers as well. This OpenStack revolution brought along a new topic called SDN. Software Defined Networking (SDN) can be seen as kind of buzzword and lot of our customers thought that they did not have a need for SDN, because their environment is not large enough, too dynamic, etc. But SDN is not just about scaling, it gives you opportunity to use NFV (Network Function Virtualization) like LbaaS, FWaaS, VPNaaS. Finally the most important reason is that Neutron supports vendor driven SDN solutions (Neutron vendor plugin) and it is possible to use this vendor SDN solution together with OpenStack in real enterprise production. The reason to use vendor plugin is that upstream Neutron solution with OpenVSwitch (DVR or L3 agent) does not provide native High Availability, scalability, performance and service provider features (L3VPN, EVPN) required by the large enterprises.</p>
<p>Our team in tcp cloud has been solving very advanced network questions and problems for different service providers for past 6 months. Based on that we had to choose SDN solution, which would let us to satisfy customer requirements and provide robust and stable cloud solution. We compared several SDN solutions from different vendors and chose OpenContrail, simply because “it works” and it is not only slideware or any other from of secret marketing product, which can be installed only by vendor behind the closed door.</p>
<p>Therefore tcp cloud together with Arrow ECS decided to create LAB environment, where we can proof and verify all marketing messages in real deployment to show customer that given solution exists, works and we know how to implement it without hidden issues.</p>
<p>This blog is first one from series of articles about OpenContrail SDN Lab testing, where we would like to cover topics like:</p>
<ul class="simple">
<li>L3VPN termination at cloud environment</li>
<li>VxLAN to EVPN Stitching for L2 Extension</li>
<li>VxLAN Routing and SDN</li>
<li>OVSDB Provides Control for VxLAN</li>
<li>Translating between SDN Types</li>
<li>MPLSoverGRE or VxLAN encapsulation</li>
<li>Kubernetes integration (container virtualization)</li>
</ul>
<div id="tor-integration-overview" class="section">
<h2>TOR INTEGRATION OVERVIEW</h2>
<p>SDN brings idea that everything can be virtualized, however there are still technological or legal limitation, which block possibility to integrate them into overlay like:</p>
<ul class="simple">
<li><strong>Legacy hardware infrastructure</strong> &#8211; PowerVM, HP Itanium, OEM appliances</li>
<li><strong>Licenses</strong> &#8211; some software cannot be operated on virtual hardware</li>
<li><strong>Physical network appliances</strong> &#8211; firewalls, load balancers, etc</li>
<li><strong>Database clusters</strong> &#8211; Oracle SuperCluster, etc</li>
</ul>
<p>Therefore there must be way how to connect the underlay world with overlay. OpenContrail provides 3 ways to connect overlay with underlay:</p>
<ul class="simple">
<li><strong>Link Local Services</strong> &#8211; it might be required for a virtual machine to access specific services running on the fabric infrastructure. For example, a VM requiring access to the backup service running in the fabric. Such access can be provided by configuring the required service as a link local service.</li>
<li><strong>Router L3/L2 gateway (VRF, EVI)</strong> &#8211; standard cloud gateway used for external routing networks. Standard use-case is OpenStack floating IPs. This will be discuss in next blog article.</li>
<li><strong>ToR switch</strong> &#8211; top-of-rack switch provides L2 connection for baremetal server or any other L2 service.</li>
</ul>
<p>This blog focuses at ToR switch integration and should answer following questions:</p>
<ul class="simple">
<li><strong>Baremetal server into overlay VN</strong></li>
<li><strong>VxLAN with OVSDB terminated at ToR switch</strong></li>
<li><strong>Multi vendor support for ToR switches with OVSDB</strong> &#8211; OpenContrail lets to use any Switch vendor with standard OVSDB protocol.</li>
<li><strong>Redundantly connected Bare Metal Servers</strong> &#8211; Physical port in virtual network is amazing, but how to solve HA for this server?</li>
<li><strong>High Availability for ToR configuration</strong> &#8211; Functional test is not equal to production setup.</li>
</ul>
<p>The beginning covers OpenContrail’s support for ToR switches with OVSDB is explained at official Juniper documentation. The next section introduces the Lab infrastructure and architecture with server role description. At the end Contrail deployment is briefly described. The last two sections cover implementation of ToR Agent with Juniper QFX and OpenVSwitch.</p>
</div>
<div id="opencontrail-support-for-tor-switch-and-ovsdb" class="section">
<h2>OPENCONTRAIL SUPPORT FOR TOR SWITCH AND OVSDB</h2>
<p>This overview is taken from <a id="id1" class="reference internal" href="http://tcpcloud.eu/en/blog/2015/07/13/opencontrail-sdn-lab-testing-1-tor-switches-ovsdb/#contrailtor">[ContrailToR]</a>. Since 2.1 release, Contrail supports extending a cluster to include bare metal servers or other virtual instances connected to a top-of-rack (ToR) switch that supports the Open vSwitch Database Management (OVSDB) Protocol. The bare metal servers and other virtual instances can belong to any of the virtual networks configured in the Contrail overlay, facilitating communication with the virtual instances running in the OpenStack cluster. Contrail policy configuration is used to control behaviour of this communication.</p>
<p>OVSDB protocol is used to configure the TOR switch and to import dynamically-learned addresses. VXLAN encapsulation is used in the data plane for communication with the TOR switch.</p>
<div id="tor-services-node-tsn" class="section">
<h3>TOR Services Node (TSN)</h3>
<p>The TSN acts as the multicast controller for the TOR switches. The TSN also provides DHCP and DNS services to the bare metal servers or virtual instances running behind TOR ports.</p>
<p>The TSN receives all the broadcast packets from the TOR, and replicates them to the required compute nodes in the cluster and to other EVPN nodes. Broadcast packets from the virtual machines in the cluster are sent directly from the respective compute nodes to the TOR switch.</p>
<p>The TSN can also act as the DHCP server for the bare metal servers or virtual instances, leasing IP addresses to them, along with other DHCP options configured in the system. The TSN also provides a DNS service for the bare metal servers.</p>
<p>Multiple TSN nodes can be configured in the system based on the scaling needs of the cluster.</p>
</div>
<div id="contrail-tor-agent" class="section">
<h3>Contrail TOR Agent</h3>
<p>A TOR agent provisioned in the Contrail cluster acts as the OVSDB client for the TOR switch, and all of the OVSDB interactions with the TOR are performed by using the TOR agent. The TOR agent programs the different OVSDB tables onto the TOR switch and receives the local unicast table entries from the TOR switch.</p>
<p>There is more information about <a id="id2" class="reference internal" href="http://tcpcloud.eu/en/blog/2015/07/13/opencontrail-sdn-lab-testing-1-tor-switches-ovsdb/#contrailtor">[ContrailToR]</a>.</p>
</div>
</div>
<div id="actual-lab-environment" class="section">
<h2>ACTUAL LAB ENVIRONMENT</h2>
<p>Arrow LAB infrastructure consists of several Juniper boxes. The following figure captures the testing rack.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/rack_oc_image1.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6369" src="http://www.opencontrail.org/wp-content/uploads/2015/07/rack_oc_image1.png" alt="rack_oc_image1" width="573" height="400" data-id="6369" /></a></p>
<p>The following diagram shows high level network design of the lab environment.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/high-level-design.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6370" src="http://www.opencontrail.org/wp-content/uploads/2015/07/high-level-design.png" alt="high-level-design" width="548" height="300" data-id="6370" /></a></p>
<p>The following diagram shows logical architecture for TOR testing. As already mentioned we use two Juniper MX5 routers and QFX5100 switches.</p>
<ul class="simple">
<li><strong>CTPx</strong> &#8211; Using 4 physical servers as compute nodes. Each compute node is KVM hypervisor with Contrail vRouter.</li>
<li><strong>BMS01</strong> &#8211; Represents physical server with one 10Gbps port connected to QFX.</li>
<li><strong>TNS01</strong> &#8211; Physical server (can be virtual) for TOR Services Node with 2 ToR agents (QFX and OpenVSwitch).</li>
<li><strong>CTL</strong> &#8211; OpenStack and OpenContrail standalone controller. It contains all OpenStack APIs, database, message queue and OpenContrail control, config and analytics roles.</li>
<li><strong>OVS</strong> &#8211; Physical server with OpenVSwitch installed that is used as ToR switch. Details are described in section with openvswitch integration.</li>
<li><strong>BMS2</strong> &#8211; Physical server connected to OVS node.</li>
</ul>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/arrowlab.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6371" src="http://www.opencontrail.org/wp-content/uploads/2015/07/arrowlab.png" alt="arrowlab" width="466" height="400" data-id="6371" /></a></p>
</div>
<div id="actual-lab-environment" class="section">
<p>The next section describes installation Contrail with TNS (ToR agent).</p>
</div>
<div id="contrail-installation" class="section">
<h2>CONTRAIL INSTALLATION</h2>
<p>The lab testing was commited on Contrail 2.1 with OpenStack IceHouse. The reason for choosing version 2.1 over 2.2 is that official Contrail 2.2 release has been available since last week. Therefore ToR in high availability setup will be discusses in next blog post, because of significant performance and availabitlity improvements in release 2.2.</p>
<p>The installation guide is available at official Juniper <a id="id3" class="reference internal" href="http://tcpcloud.eu/en/blog/2015/07/13/opencontrail-sdn-lab-testing-1-tor-switches-ovsdb/#site">[site]</a>. The following output shows our testbed.py file, where hosts are:</p>
<ul class="simple">
<li><strong>host1</strong> &#8211; OpenStack and OpenContrail standalone controller. It contains all OpenStack APIs, database, message queue and OpenContrail control, config and analytics role.</li>
<li><strong>host2 &#8211; 5</strong> &#8211; Compute nodes</li>
<li><strong>host6</strong> &#8211; TNS node with ToR agents. We installed first ToR agent by Fabric provisioning and second ToR manually in OpenVSwitch section.</li>
</ul>
<p>&nbsp;</p>
<pre><span style="font-family: 'courier new', courier;">from fabric.api import env 
#Management ip addresses of hosts in the clusterhost1='ubuntu@10.10.90.129' host2='ubuntu@10.100.10.2' host3='ubuntu@10.100.10.3' host4='ubuntu@10.100.10.4' host5='ubuntu@10.100.10.5' host6='ubuntu@10.100.10.6'ext_routers=[]router_asn= 65412  
host_build='ubuntu@10.10.90.129'
env.roledefs ={'all': [host1, host2, host3,host6],
     'cfgm': [host1], 
     'openstack': [host1], 
     'control': [host1], 
     'compute': [host2,host3,host4,host5,host6], 
     'collector': [host1], 
     'webui': [host1], 
     'database': [host1], 
     'build': [host_build], 
     'storage-master': [host1], 
     'storage-compute': [host2, host3,host4,host5], 
     'tsn': [host6], # Optional, Only to enable TSN. Only compute can support TSN'toragent': [host6], #, Optional, Only to enable Tor Agent. Only compute can support Tor Agent} 

env.openstack_admin_password ='arrowlab' 
env.hostnames ={'all': ['ctl01', 'cpt01', 'cpt02', 'cpt03', 'cpt04','tns01']} 

env.passwords ={ 
      host1: 'ubuntu', 
      host2: 'ubuntu', 
      host3: 'ubuntu', 
      host4: 'ubuntu', 
      host5: 'ubuntu', 
      host6: 'ubuntu', 
      host_build: 'ubuntu', 
} 

env.ostypes ={ 
      host1:'ubuntu', 
      host2:'ubuntu', 
      host3:'ubuntu', 
      host4:'ubuntu', 
      host5:'ubuntu', 
      host6:'ubuntu', 
} 

env.tor_agent ={ 
host6: [{'tor_ip':'10.100.10.1', # IP address of the TOR'tor_id':'1', # Numeric value to uniquely identify TOR 'tor_type':'ovs''tor_ovs_port':'9999', # the TCP port to connect on the TOR'tor_ovs_protocol':'tcp', # always tcp, for now'tor_tsn_ip':'10.100.10.6', # IP address of the TSN for this TOR'tor_tsn_name':'tns01', # Name of the TSN node'tor_name':'qfx5100', # Name of the TOR switch'tor_tunnel_ip':'10.10.80.6', # IP address of Data tunnel endpoint'tor_vendor_name':'QFX5100', # Vendor name for TOR switch'tor_http_server_port':'8085', # HTTP port for TOR Introspect}]}

</span></pre>
<h2>CONTRAIL BAREMETAL TOR IMPLEMENTATION WITH JUNIPER QFX5100</h2>
<p>This section shows how to setup Juniper QFX as ToR switch with baremetal server connection to the virtual network.</p>
<pre><span style="font-family: 'courier new', courier;"><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/torQFX1.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6374" src="http://www.opencontrail.org/wp-content/uploads/2015/07/torQFX1.png" alt="torQFX1" width="471" height="350" data-id="6374" /></a></span></pre>
<p class="section">Scenario for testing:</p>
<p class="section">1. Create virtual network <em>vxlannet</em> 10.0.10.0/24 and set VxLAN encapsulation through VNI 10<br />
2. Boot two instances VM1 (10.0.10.4) and VM2 (10.0.10.3) at two compute nodes into created virtual network <em>vxlannet3. </em><br />
3. Configure QFX for managing by OVSDB.<br />
4. Configure QFX port xe-0/0/40.1000 through Contrail as L2 10.0.10.100 to network <em>vxlannet</em>.<br />
5. Verify connectivity and configuration.</p>
<p>Step 1. and 2. is not covered in this blog post.</p>
<div id="qfx5100-configuration" class="section">
<h3>QFX5100 Configuration</h3>
<p>OVSDB software package must be installed in order to enable following configuration in QFX side. We run Junos version 14.1X53-D15.2 with JUNOS SDN Software Suite 14.1X53-D15.2.</p>
<p>The following output shows commands for configuration QFX switch to enable managing interface xe-0/0/40 through ovsdb. This configuration parameters have to meet values from <em>testbed.py</em>.</p>
<pre><span style="font-family: 'courier new', courier;">set interfaces lo0 unit 0 family inet address 10.10.80.6/32 
set switch-options ovsdb-managed 
set switch-options vtep-source-interface lo0.0 
set protocols ovsdb passive-connection protocol tcp port 6632 
set protocols ovsdb interfaces xe-0/0/40 

</span></pre>
<h3>Contrail Configuration</h3>
<p>Configuration for ToR agent was already defined in testbed.py, therefore the rest can be done in Contrail WebUI.</p>
<p>On Contrail side we had to add physical device QFX. After that we added physical and logical port for bare metal server.</p>
<p>In Contrail WebUI go to <em>Configure &gt; Physical Devices &gt; Physical Routers</em> and create new entry for the TOR switch, providing the TOR’s IP address and VTEP address. The router name should match the hostname of the TOR. Also configure the TSN and TOR agent addresses for the TOR.</p>
<pre><span style="font-family: 'courier new', courier;"><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/edit-physical-qfx.png"><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-6375" src="http://www.opencontrail.org/wp-content/uploads/2015/07/edit-physical-qfx.png" alt="edit-physical-qfx" width="698" height="516" data-id="6375" /></a>
</span></pre>
<p>Go to <em>Configure &gt; Physical Devices &gt; Interfaces</em> and add physical and logical interface to be configured on the TOR. The name of the logical interface must match the name on the TOR (xe-0/0/40 and xe-0/0/40.1000). Also enter other logical interface configurations, such as VLAN ID, MAC address, and IP address of the bare metal server and the virtual network to which it belongs.</p>
<p>We made several tests and this configuration shows connection of bare metal server with VLAN tagged with ID 1000.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/logical-port-qfx.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6376" src="http://www.opencontrail.org/wp-content/uploads/2015/07/logical-port-qfx.png" alt="logical-port-qfx" width="980" height="300" data-id="6376" /></a></p>
<p>The following output shows configuration changes done by Contrail on interfaces and VLAN section.</p>
<pre><span style="font-family: 'courier new', courier;">softtronik@QFX5100_VC# show interfaces xe-0/0/40 
flexible-vlan-tagging; 
encapsulation extended-vlan-bridge; 
unit 1000 { 
           vlan-id 1000; 
} 

softtronik@QFX5100_VC# show vlans 
Contrail-c68a622b-9248-4535-bf04-4859012d7a2a { 
           interface xe-0/0/40.1000; 
           vxlan { 
                  vni 10; 
           }} </span></pre>
<p>To list interfaces managed via ovsdb, use <em>show ovsdb interface</em> command.</p>
<pre><span style="font-family: 'courier new', courier;">softtronik@QFX5100_VC&gt; show ovsdb interface 
Interface           VLAN ID           Bridge-domain 
xe-0/0/40           1000              Contrail-c68a622b-9248-4535-bf04-4859012d7a2a</span></pre>
<p>List all learned MAC addresses and connection with particular VTEP with <em>show ovsdb mac</em>. Grep only remote addresses by adding keyword remote at the end of the command.</p>
<pre><span style="font-family: 'courier new', courier;">softtronik@QFX5100_VC&gt; show ovsdb mac 
Logical Switch Name: Contrail-c68a622b-9248-4535-bf04-4859012d7a2a 
Mac                                    IP                                 Encapsulation                                          Vtep 
Address                                Address                                                                                   Address 
ff:ff:ff:ff:ff:ff                      0.0.0.0                            Vxlan over Ipv4                                        10.10.80.6 
10:0e:7e:bf:9e:ec                      0.0.0.0                            Vxlan over Ipv4                                        10.10.80.6 
02:30:84:c3:d1:13                      0.0.0.0                            Vxlan over Ipv4                                        10.100.10.2 
02:e1:bb:af:65:11                      0.0.0.0                            Vxlan over Ipv4                                        10.100.10.4 
02:fc:94:91:42:f2                      0.0.0.0                            Vxlan over Ipv4                                        10.100.10.5 
1a:7f:6d:fb:0e:3d                      0.0.0.0                            Vxlan over Ipv4                                        10.100.10.7 
40:a6:77:9a:b3:38                      0.0.0.0                            Vxlan over Ipv4                                        10.10.80.4 
ff:ff:ff:ff:ff:ff                      0.0.0.0                            Vxlan over Ipv4                                        10.100.10.6 

softtronik@QFX5100_VC&gt; show ovsdb virtual-tunnel-end-point 

Encapsulation                   Ip Address                               Num of MAC's 
VXLAN over IPv4                 10.10.80.4                               1
VXLAN over IPv4                 10.10.80.6                               2 
VXLAN over IPv4                 10.100.10.2                              1 
VXLAN over IPv4                 10.100.10.4                              1 
VXLAN over IPv4                 10.100.10.5                              1 
VXLAN over IPv4                 10.100.10.6                              1 
VXLAN over IPv4                 10.100.10.7                              1</span></pre>
<p>With this command we can see all Vtep addresses present in out network.</p>
<pre><span style="font-family: 'courier new', courier;">softtronik@QFX5100_VC&gt; show vlans 
Routing instance        VLAN name                                               Tag              Interfaces 
default-switch          Contrail-c68a622b-9248-4535-bf04-4859012d7a2a           NA               vtep.32769* 
                                                                                                 vtep.32770* 
                                                                                                 vtep.32771* 
                                                                                                 vtep.32772* 
                                                                                                 vtep.32773* 
                                                                                                 vtep.32774* 
                                                                                                 xe-0/0/40.1000*</span></pre>
<p>Vtep interfaces can be also listed with <em>show interfaces terse vtep</em> command.</p>
<pre><span style="font-family: 'courier new', courier;">softtronik@QFX5100_VC&gt; show interfaces terse vtep 
Interface                Admin            Link            Proto            Local           Remote 
vtep                     up               up 
vtep.32768               up               up 
vtep.32769               up               up              eth-switch   
vtep.32770               up               up              eth-switch 
vtep.32771               up               up              eth-switch 
vtep.32772               up               up              eth-switch 
vtep.32773               up               up              eth-switch 
vtep.32774               up               up              eth-switch</span></pre>
<p>To see detailed information, use the previous command with particular interface.</p>
<pre><span style="font-family: 'courier new', courier;">softtronik@QFX5100_VC&gt; show interfaces vtep.32769 
     Logical interface vtep.32769 (Index 576)(SNMP ifIndex 544) 
           Flags: Up SNMP-Traps Encapsulation: ENET2 
           VXLAN Endpoint Type: Remote, VXLAN Endpoint Address: 10.100.10.2, L2 Routing Instance: default-switch, L3 Routing Instance: default 
           Input packets : 0 
           Output packets: 8 
           Protocol eth-switch, MTU: 1600 
              Flags: Trunk-Mode

</span></pre>
<div class="section">
<div id="redundant-connection-of-bare-metal-servers" class="section">
<h3>Redundant Connection of Bare Metal Servers</h3>
<p>We wanted to use MC-LAG (QFX in virtual chassis) to enable run LACP on both ports, but MC-LAG is not currently supported with VxLAN (but it’s on the roadmap). Therefore only viable option is to connect both port into same Virtual Network (VNI) and configure active-passive bonding on the bare metal server.</p>
</div>
</div>
<h2>CONTRAIL BAREMETAL TOR IMPLEMENTATION WITH OPENVSWITCH VTEP</h2>
<p>We tested and verified Juniper QFX5100 works well as TOR switch in the previous section, which was no surprise to us because they are from the same vendor. At this part we want to show that Contrail in not a vendor locked-in solution by using standard network protocols. There are several switch vendors (Cumulus, Arista) who support OVSDB capability in their boxes. We have decided to proof this openness on OpenVSwitch.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/OVS.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6377" src="http://www.opencontrail.org/wp-content/uploads/2015/07/OVS.png" alt="OVS" width="528" height="450" data-id="6377" /></a></p>
<p>We deployed another two physical server OVS, BSM02 and ToR agent TNS1-02. OVS server with openvswitch represents same role as Juniper QFX. We tested 3 use cases:</p>
<ul class="simple">
<li>simulate netns <em>ns1</em> namespaces as BMS endpoint</li>
<li>install KVM on OVS and launch VM5 as BMS endpoint</li>
<li>use physical NIC eth3 and connect BMS02 physical bare metal server</li>
</ul>
<p class="section">Scenario for testing:</p>
<p>1. Create TOR agent &#8211; deploy TOR agent for managing OVS<br />
2. Setup OVS &#8211; install openvswitch-vtep, configure physical switch and connect namespace.<br />
3. Connect KVM VM to cloud &#8211; install kvm, launch VM5 with OVS interface and connect through a new logical port.<br />
4. Connect BMS to cloud &#8211; add OVS physical interface eth2 and verify connectivity from BMS02.</p>
<h3>Create TOR agent</h3>
<p class="section">In previous chapter we used tns1-01 TOR agent for QFX5100. If we want to manage another switch via OVSDB, next TOR agent service has to be started. It can be done on the same TNS node. Provisioning can be done through Fabric, but we show how to do that manually. Start witch copying config file of tns1-01 agent.</p>
<pre><span style="font-family: 'courier new', courier;">root@tns01:~# cp /etc/contrail/contrail-tor-agent-1.conf /etc/contrail/contrail-tor-agent-2.conf</span></pre>
<p>Then we had to change some values in this copied file.</p>
<pre><span style="font-family: 'courier new', courier;">[DEFAULT]agent_name=tns01-2 
log_file=/var/log/contrail/contrail-tor-agent-2.log 
http_server_port=8086 
[TOR]tor_ip=10.100.10.7</span></pre>
<p>We have copy of supervisor file to start new service also.</p>
<pre><span style="font-family: 'courier new', courier;">root@tns01:~# cp /etc/contrail/supervisord_vrouter_files/contrail-tor-agent-1.ini /etc/contrail/supervisord_vrouter_files/contrail-tor-agent-2.ini</span></pre>
<p>And change these configuration values.</p>
<pre><span style="font-family: 'courier new', courier;">command=/usr/bin/contrail-tor-agent --config_file /etc/contrail/contrail-tor-agent-2.conf 
stdout_logfile=/var/log/contrail/contrail-tor-agent-2-stdout.log</span></pre>
<p>Now restart supervisor to see changes.</p>
<pre><span style="font-family: 'courier new', courier;">root@tns01:~# service supervisor-vrouter restart</span></pre>
<p>And verify changes:</p>
<pre><span style="font-family: 'courier new', courier;">root@tns01:~# contrail-status 
== Contrail vRouter== 
supervisor-vrouter:            active 
contrail-tor-agent-1           active 
contrail-tor-agent-2           active 
contrail-vrouter-agent         active 
contrail-vrouter-nodemgr       active 

</span></pre>
<h3>Setup OVS</h3>
<p class="section">We need to install at least openvswitch-2.3.1, because it has ovs-vtep with VTEP simulator <a id="id4" class="reference internal" href="http://tcpcloud.eu/en/blog/2015/07/13/opencontrail-sdn-lab-testing-1-tor-switches-ovsdb/#vtep">[vtep]</a>. However Ubuntu 14.04.2 contains 2.0.2. Therefore you have to build your own packages or use source tarball. We found packages at PPA <a class="reference external" href="https://launchpad.net/~vshn/+archive/ubuntu/openvswitch">https://launchpad.net/~vshn/+archive/ubuntu/openvswitch</a>.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# cat /etc/apt/sources.list.d/ovs.list 
deb http://ppa.launchpad.net/vshn/openvswitch/ubuntu trusty main 
deb-src http://ppa.launchpad.net/vshn/openvswitch/ubuntu trusty main 

root@ovs:~# apt-get install openvswitch-vtep</span></pre>
<p>We have to delete default existing database created during installation.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~#rm /etc/openvswitch/*.db</span></pre>
<p>And create two new databases: ovs.db and vtep.db</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~#ovsdb-tool create /etc/openvswitch/ovs.db /usr/share/openvswitch/vswitch.ovsschema ; ovsdb-tool create /etc/openvswitch/vtep.db /usr/share/openvswitch/vtep.ovsschema</span></pre>
<p>Restart services and make sure, that the ptcp port number matches the port number in contrail-tor-agent-2.conf on TNS node.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~#service openvswitch-switch stop 
root@ovs:~#ovsdb-server --pidfile --detach --log-file --remote punix:/var/run/openvswitch/db.sock --remote=db:hardware_vtep,Global,managers --remote ptcp:6632 /etc/openvswitch/ovs.db /etc/openvswitch/vtep.db root@ovs:~#ovs-vswitchd --log-file --detach --pidfile unix:/var/run/openvswitch/db.sock</span></pre>
<p>Verify creation of databases with:</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~#ovsdb-client list-dbs unix:/var/run/openvswitch/db.sock 
Open_vSwitch 
hardware_vtep</span></pre>
<p>First we need to test our installation with connecting namespace to virtual network. Start with creating bridge.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~#ovs-vsctl add-br TOR1 
root@ovs:~#vtep-ctl add-ps TOR1</span></pre>
<p>Setup VTEP of bridge. IP addresses are underlay addresses of our node with OVS.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~#vtep-ctl set Physical_Switch TOR1 tunnel_ips=10.100.10.7 
root@ovs:~#vtep-ctl set Physical_Switch TOR1 management_ips=10.100.10.7 
root@ovs:~#python /usr/share/openvswitch/scripts/ovs-vtep --log-file=/var/log/openvswitch/ovs-vtep.log --pidfile=/var/run/openvswitch/ovs-vtep.pid --detach TOR1</span></pre>
<p>Now create namespace and link its interface with OVS interface.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~#ip netns add ns1 
root@ovs:~#ip link add nstap1 type veth peer name tortap1 
root@ovs:~#ovs-vsctl add-port TOR1 tortap1 
root@ovs:~#ip link set nstap1 netns ns1 
root@ovs:~#ip netns exec ns1 ip link set dev nstap1 up 
root@ovs:~#ip link set dev tortap1 up</span></pre>
<p>And configure namespace to be able to communicate with world.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~#ip netns
root@ovs:~#ip netns exec ns1 ip a a 127.0.0.1/8 dev lo
root@ovs:~#ip netns exec ns1 ip a
root@ovs:~#ip netns exec ns1 ip a a 10.0.10.120/24 dev nstap1
root@ovs:~#ip netns exec ns1 ping 10.0.10.120
root@ovs:~#ip netns exec ns1 ip link set up dev lo
root@ovs:~#ip netns exec ns1 ping 10.0.10.120</span></pre>
<p>You can verify previous steps with looking into database.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# vtep-ctl list Physical_Switch
_uuid               : f00f2242-409e-43fc-8d4f-32e2225937d8
description         : "OVS VTEP Emulator"
management_ips      : ["10.100.10.7"]
name                : "TOR1"
ports               : [82afe753-25f8-4127-839b-2c5c8f7948b2]
switch_fault_status : []
tunnel_ips          : ["10.100.10.7"]
tunnels             : []</span></pre>
<p>Now we have to add TOR1 as a new physical device in Contrail managed by TOR agent tns01-2.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-6380" src="http://www.opencontrail.org/wp-content/uploads/2015/07/edit-physical-router.png" alt="edit-physical-router" width="697" height="514" data-id="6380" /></p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-6381" src="http://www.opencontrail.org/wp-content/uploads/2015/07/physical-routers.png" alt="physical-routers" width="806" height="187" data-id="6381" /></p>
<p>Then create physical port tortap1 with logical tortap1.0 interface, which goes to our ns1 namespace.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/interfaces.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6382" src="http://www.opencontrail.org/wp-content/uploads/2015/07/interfaces.png" alt="interfaces" width="972" height="300" data-id="6382" /></a></p>
<p>&nbsp;</p>
<p>We can verify Contrail configuration by following output.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# vtep-ctl list-ls
Contrail-c68a622b-9248-4535-bf04-4859012d7a2a</span></pre>
<p>Check namespace IP addresses.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# ip netns exec ns1 ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
7: nstap1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 1a:7f:6d:fb:0e:3d brd ff:ff:ff:ff:ff:ff
    inet 10.0.10.120/24 scope global nstap1
       valid_lft forever preferred_lft forever
    inet6 fe80::187f:6dff:fefb:e3d/64 scope link
       valid_lft forever preferred_lft forever</span></pre>
<p>Try to ping VM4 from ns1.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# ip netns exec ns1 ping 10.0.10.3
PING 10.0.10.3 (10.0.10.3) 56(84) bytes of data.
64 bytes from 10.0.10.3: icmp_seq=1 ttl=64 time=1.25 ms
64 bytes from 10.0.10.3: icmp_seq=2 ttl=64 time=0.311 ms
64 bytes from 10.0.10.3: icmp_seq=3 ttl=64 time=0.307 ms
64 bytes from 10.0.10.3: icmp_seq=4 ttl=64 time=0.270 ms
^C
--- 10.0.10.3 ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 2999ms
rtt min/avg/max/mdev = 0.270/0.536/1.256/0.416 ms</span></pre>
<p>Following output shows all interface on physical server OVS.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:95:60:e8 brd ff:ff:ff:ff:ff:ff
    inet 10.10.70.135/24 brd 10.10.70.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::250:56ff:fe95:60e8/64 scope link
       valid_lft forever preferred_lft forever
3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:95:6b:14 brd ff:ff:ff:ff:ff:ff
    inet 10.100.10.7/24 brd 10.100.10.255 scope global eth1
       valid_lft forever preferred_lft forever
    inet6 fe80::250:56ff:fe95:6b14/64 scope link
       valid_lft forever preferred_lft forever
4: ovs-system: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default
    link/ether 4a:4f:14:53:c6:df brd ff:ff:ff:ff:ff:ff
5: TOR1: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default
    link/ether 2a:11:8c:74:61:46 brd ff:ff:ff:ff:ff:ff
6: tortap1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master ovs-system state UP group default qlen 1000
    link/ether 16:62:97:5a:62:e8 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::1462:97ff:fe5a:62e8/64 scope link
       valid_lft forever preferred_lft forever
8: vtep_ls1: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default
    link/ether 62:2b:86:c3:c2:4b brd ff:ff:ff:ff:ff:ff </span></pre>
<p>Following output shows openvswitch configuration. Patch ports 0000-tortap1-p and 0000-tortap1-lwere created by Contrail.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# ovs-vsctl show
93d90385-f9c6-4cfc-b67d-4f64eec15479
    Bridge "TOR1"
        Port "TOR1"
            Interface "TOR1"type: internal
        Port "tortap1"
            Interface "tortap1"
        Port "0000-tortap1-p"
            Interface "0000-tortap1-p"type: patch
                options: {peer="0000-tortap1-l"}
    Bridge "vtep_ls1"
        Port "vx4"
            Interface "vx4"type: vxlan
                options: {key="10", remote_ip="10.100.10.2"}
        Port "vx2"
            Interface "vx2"type: vxlan
                options: {key="10", remote_ip="10.100.10.5"}
        Port "vx5"
            Interface "vx5"type: vxlan
                options: {key="10", remote_ip="10.100.10.6"}
        Port "vx3"
            Interface "vx3"type: vxlan
                options: {key="10", remote_ip="10.100.10.4"}
        Port "vx9"
            Interface "vx9"type: vxlan
                options: {key="10", remote_ip="10.10.80.6"}
        Port "vtep_ls1"
            Interface "vtep_ls1"type: internal
        Port "0000-tortap1-l"
            Interface "0000-tortap1-l"type: patch
                options: {peer="0000-tortap1-p"}</span></pre>
<h4>Connect KVM VM to the Cloud</h4>
<p>Now we want to try to boot VM5 on OVS server and connect it into our virtual network as a bare metal server. At first we need to install qemu and boot a virtual machine.</p>
<pre><span style="font-family: 'courier new', courier;">sudo apt-get install qemu-system-x86 ubuntu-vm-builder uml-utilities
sudo ubuntu-vm-builder kvm precise</span></pre>
<p>Once that is done, create a VM, if necessary, and edit its Domain XML file:</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# virsh list
 Id    Name                           State
----------------------------------------------------
 7     ubuntu                         running

% virsh destroy ubuntu
% virsh edit ubuntu</span></pre>
<p>Look at the Domain XML file the section. There should be one XML section for each interface the VM</p>
<div id="stcpDiv">
<p class="section">has.</p>
<div class="highlight-bash">
<div class="highlight">
<pre>&lt;interface <span class="nb">type</span><span class="o">=</span><span class="s1">'network'</span>&gt;
 &lt;mac <span class="nv">address</span><span class="o">=</span><span class="s1">'52:54:00:3a:b6:13'</span>/&gt;
 &lt;<span class="nb">source </span><span class="nv">network</span><span class="o">=</span><span class="s1">'default'</span>/&gt;
 &lt;address <span class="nb">type</span><span class="o">=</span><span class="s1">'pci'</span><span class="nv">domain</span><span class="o">=</span><span class="s1">'0x0000'</span><span class="nv">bus</span><span class="o">=</span><span class="s1">'0x00'</span><span class="nv">slot</span><span class="o">=</span><span class="s1">'0x03'</span><span class="k">function</span><span class="o">=</span><span class="s1">'0x0'</span>/&gt;
&lt;/interface&gt;
</pre>
</div>
</div>
<p class="section">And change it to something like this:</p>
<div id="stcpDiv">
<div class="highlight-bash">
<div class="highlight">
<pre>&lt;interface <span class="nb">type</span><span class="o">=</span><span class="s1">'bridge'</span>&gt;
 &lt;mac <span class="nv">address</span><span class="o">=</span><span class="s1">'52:54:00:3a:b6:13'</span>/&gt;
 &lt;<span class="nb">source </span><span class="nv">bridge</span><span class="o">=</span><span class="s1">'TOR1'</span>/&gt;
 &lt;virtualport <span class="nb">type</span><span class="o">=</span><span class="s1">'openvswitch'</span>/&gt;
 &lt;address <span class="nb">type</span><span class="o">=</span><span class="s1">'pci'</span><span class="nv">domain</span><span class="o">=</span><span class="s1">'0x0000'</span><span class="nv">bus</span><span class="o">=</span><span class="s1">'0x00'</span><span class="nv">slot</span><span class="o">=</span><span class="s1">'0x03'</span><span class="k">function</span><span class="o">=</span><span class="s1">'0x0'</span>/&gt;
&lt;/interface&gt;
</pre>
</div>
</div>
<p>Start VM5 and verify that it uses openvswitch interface. There is automatically created interface</p>
<div id="stcpDiv">
<p class="section">vnet0.</p>
<div class="highlight-bash">
<div class="highlight">
<pre>    % virsh start ubuntu

&lt;interface <span class="nb">type</span><span class="o">=</span><span class="s1">'bridge'</span>&gt;
  &lt;mac <span class="nv">address</span><span class="o">=</span><span class="s1">'52:54:00:3a:b6:13'</span>/&gt;
  &lt;<span class="nb">source </span><span class="nv">bridge</span><span class="o">=</span><span class="s1">'TOR1'</span>/&gt;
  &lt;virtualport <span class="nb">type</span><span class="o">=</span><span class="s1">'openvswitch'</span>&gt;
    &lt;parameters <span class="nv">interfaceid</span><span class="o">=</span><span class="s1">'5def61f9-7123-43a5-b7ae-35f0fbd22fca'</span>/&gt;
  &lt;/virtualport&gt;
  &lt;target <span class="nv">dev</span><span class="o">=</span><span class="s1">'vnet0'</span>/&gt;
  &lt;model <span class="nb">type</span><span class="o">=</span><span class="s1">'virtio'</span>/&gt;
  &lt;<span class="nb">alias </span><span class="nv">name</span><span class="o">=</span><span class="s1">'net0'</span>/&gt;
  &lt;address <span class="nb">type</span><span class="o">=</span><span class="s1">'pci'</span><span class="nv">domain</span><span class="o">=</span><span class="s1">'0x0000'</span><span class="nv">bus</span><span class="o">=</span><span class="s1">'0x00'</span><span class="nv">slot</span><span class="o">=</span><span class="s1">'0x03'</span><span class="k">function</span><span class="o">=</span><span class="s1">'0x0'</span>/&gt;
&lt;/interface&gt;
</pre>
</div>
</div>
<p class="section">Now we can add a new port vnet0 as physical and logical port in Contrail.</p>
</div>
</div>
</div>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-6383" src="http://www.opencontrail.org/wp-content/uploads/2015/07/add-vnet0.png" alt="add-vnet0" width="700" height="433" data-id="6383" /></p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/logical-ports-vnet0.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6384" src="http://www.opencontrail.org/wp-content/uploads/2015/07/logical-ports-vnet0.png" alt="logical-ports-vnet0" width="833" height="300" data-id="6384" /></a></p>
<p>We can check new patch interfaces in openvswitch.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# ovs-vsctl show
93d90385-f9c6-4cfc-b67d-4f64eec15479
    Bridge "TOR1"
        Port "vnet0"
            Interface "vnet0"
        Port "TOR1"
            Interface "TOR1"type: internal
        Port "tortap1"
            Interface "tortap1"
        Port "0000-vnet0-p"
            Interface "0000-vnet0-p"type: patch
                options: {peer="0000-vnet0-l"}
        Port "0000-tortap1-p"
            Interface "0000-tortap1-p"type: patch
                options: {peer="0000-tortap1-l"}
    Bridge "vtep_ls1"
        Port "vx4"
            Interface "vx4"type: vxlan
                options: {key="10", remote_ip="10.100.10.2"}
        Port "0000-vnet0-l"
            Interface "0000-vnet0-l"type: patch
                options: {peer="0000-vnet0-p"}
        Port "vx2"
            Interface "vx2"type: vxlan
                options: {key="10", remote_ip="10.100.10.5"}
        Port "vx5"
            Interface "vx5"type: vxlan
                options: {key="10", remote_ip="10.100.10.6"}
        Port "vx3"
            Interface "vx3"type: vxlan
                options: {key="10", remote_ip="10.100.10.4"}
        Port "vtep_ls1"
            Interface "vtep_ls1"type: internal
        Port "0000-tortap1-l"
            Interface "0000-tortap1-l"type: patch
                options: {peer="0000-tortap1-p"}</span></pre>
<p>We can open console at VM5, manually set IP address and try to ping VM4.</p>
<p><img loading="lazy" decoding="async" class="aligncenter size-full wp-image-6385" src="http://www.opencontrail.org/wp-content/uploads/2015/07/ubuntu-vm-ping.png" alt="ubuntu-vm-ping" width="796" height="545" data-id="6385" /></p>
<p>We can check the same thing from baremetal namespace.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# ip netns exec ns1 ping 10.0.10.121
PING 10.0.10.121 (10.0.10.121) 56(84) bytes of data.
64 bytes from 10.0.10.121: icmp_seq=1 ttl=64 time=0.709 ms
64 bytes from 10.0.10.121: icmp_seq=2 ttl=64 time=0.432 ms
64 bytes from 10.0.10.121: icmp_seq=3 ttl=64 time=0.302 ms
^C
--- 10.0.10.121 ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 1999ms
rtt min/avg/max/mdev = 0.302/0.481/0.709/0.169 ms</span></pre>
<p>The following screen shows L2 routes at vRouter with VM4, where you can see all details about VxLAN tunnel.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/l2-vxlan-tunnel.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6386" src="http://www.opencontrail.org/wp-content/uploads/2015/07/l2-vxlan-tunnel.png" alt="l2-vxlan-tunnel" width="692" height="350" data-id="6386" /></a></p>
<h3>Connect BMS to cloud</h3>
<p class="section">Last test use case is to connect another baremetal server BMS02 through the physical NIC of OVS server.In this case OVS server represents a true switch.Add a physical interface eth3to you server with OVS.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~#ovs-vsctl add-port TOR1 eth3

root@ovs:~# ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:95:60:e8 brd ff:ff:ff:ff:ff:ff
    inet 10.10.70.135/24 brd 10.10.70.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::250:56ff:fe95:60e8/64 scope link
       valid_lft forever preferred_lft forever
...
24: eth3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq master ovs-system state UP group default qlen 1000
    link/ether 00:50:56:95:e0:21 brd ff:ff:ff:ff:ff:ff
    inet6 fe80::250:56ff:fe95:e021/64 scope link
       valid_lft forever preferred_lft forever</span></pre>
<p>Create physical and logical ports for eth3.</p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2015/07/logical-ports-eth3.png"><img loading="lazy" decoding="async" class="aligncenter wp-image-6387" src="http://www.opencontrail.org/wp-content/uploads/2015/07/logical-ports-eth3.png" alt="logical-ports-eth3" width="722" height="300" data-id="6387" /></a></p>
<p>Check new ports in openvswitch.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# ovs-vsctl show
93d90385-f9c6-4cfc-b67d-4f64eec15479
    Bridge "TOR1"
        ...
        Port "TOR1"
            Interface "TOR1"type: internal
        Port "0000-eth3-p"
            Interface "0000-eth3-p"type: patch
                options: {peer="0000-eth3-l"}
        Port "eth3"
            Interface "eth3"
        ...
    Bridge "vtep_ls1"
        Port "vx17"
            Interface "vx17"type: vxlan
                options: {key="10", remote_ip="10.10.80.4"}
        Port "vx4"
            Interface "vx4"type: vxlan
                options: {key="10", remote_ip="10.100.10.2"}
        Port "vx2"
            Interface "vx2"type: vxlan
                options: {key="10", remote_ip="10.100.10.5"}
        Port "0000-vnet0-l"
            Interface "0000-vnet0-l"type: patch
                options: {peer="0000-vnet0-p"}
        Port "0000-tortap1-l"
            Interface "0000-tortap1-l"type: patch
                options: {peer="0000-tortap1-p"}
        Port "vx5"
            Interface "vx5"type: vxlan
                options: {key="10", remote_ip="10.100.10.6"}
        Port "vx3"
            Interface "vx3"type: vxlan
                options: {key="10", remote_ip="10.100.10.4"}
        Port "vtep_ls1"
            Interface "vtep_ls1"type: internal
        Port "0000-eth3-l"
            Interface "0000-eth3-l"type: patch
                options: {peer="0000-eth3-p"}</span></pre>
<p>As you can see it is possible to ping cloud instance from our bare metal server.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs2:~# ping 10.0.10.3
PING 10.0.10.3 (10.0.10.3) 56(84) bytes of data.
64 bytes from 10.0.10.3: icmp_seq=2 ttl=64 time=1.10 ms
64 bytes from 10.0.10.3: icmp_seq=3 ttl=64 time=0.387 ms
64 bytes from 10.0.10.3: icmp_seq=4 ttl=64 time=0.428 ms
64 bytes from 10.0.10.3: icmp_seq=5 ttl=64 time=0.378 ms
64 bytes from 10.0.10.3: icmp_seq=6 ttl=64 time=0.419 ms
64 bytes from 10.0.10.3: icmp_seq=7 ttl=64 time=0.382 ms
^C
--- 10.0.10.3 ping statistics ---
7 packets transmitted, 6 received, 14% packet loss, time 6005ms
rtt min/avg/max/mdev = 0.378/0.516/1.102/0.262 ms</span></pre>
<h3>Verification</h3>
<p>OVS maintains network information in database. To list existing tables use:</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# ovsdb-client list-tables unix:/var/run/openvswitch/db.sock hardware_vtep
Table
---------------------
Physical_Port
Physical_Locator_Set
Physical_Locator
Logical_Binding_Stats
Arp_Sources_Remote
Manager
Mcast_Macs_Local
Global
Ucast_Macs_Local
Logical_Switch
Physical_Switch
Ucast_Macs_Remote
Tunnel
Mcast_Macs_Remote
Logical_Router
Arp_Sources_Local</span></pre>
<p>To view the content of these tables in readable format use vtep-ctl listcommand with table’s name at the end.The list of physical interfaces associated with ovs.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# vtep-ctl list Physical_Port
        _uuid               : ac4a8bb8-bd11-47d3-a5ac-9828c5f68ffc
        description         : ""
        name                : "eth3"
        port_fault_status   : []
        vlan_bindings       : {0=4f016591-56ce-496f-996e-a93203061e07}
        vlan_stats          : {0=288fe0f7-d7b8-430a-beb4-0c0a2c536a9c}

        _uuid               : 41f87dae-6568-4fc9-97fc-46ec3d2fbfdd
        description         : ""
        name                : "vnet0"
        port_fault_status   : []
        vlan_bindings       : {0=4f016591-56ce-496f-996e-a93203061e07}
        vlan_stats          : {0=12d70df8-6448-4784-af0d-754f37847942}

        _uuid               : 82afe753-25f8-4127-839b-2c5c8f7948b2
        description         : ""
        name                : "tortap1"
        port_fault_status   : []
        vlan_bindings       : {0=4f016591-56ce-496f-996e-a93203061e07}
        vlan_stats          : {0=e68cc29d-72c3-4809-a013-32c91a119b11}</span></pre>
<p>To see remote MAC addresses and their next hop VTEPs we have to first find out name of our logical switch.</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# vtep-ctl list-ls
Contrail-c68a622b-9248-4535-bf04-4859012d7a2a</span></pre>
<p>Then list remote macs:</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# vtep-ctl list-remote-macs Contrail-c68a622b-9248-4535-bf04-4859012d7a2a
ucast-mac-remote
  02:30:84:c3:d1:13 -&gt; vxlan_over_ipv4/10.100.10.2
  02:e1:bb:af:65:11 -&gt; vxlan_over_ipv4/10.100.10.4
  02:fc:94:91:42:f2 -&gt; vxlan_over_ipv4/10.100.10.5
  40:a6:77:9a:b3:38 -&gt; vxlan_over_ipv4/10.10.80.4

mcast-mac-remote
  unknown-dst -&gt; vxlan_over_ipv4/10.100.10.6</span></pre>
<p>As we can see, unknown traffic is handled by TOR agent.To list local MACs type:</p>
<pre><span style="font-family: 'courier new', courier;">root@ovs:~# vtep-ctl list-local-macs Contrail-c68a622b-9248-4535-bf04-4859012d7a2a
ucast-mac-local
  1a:7f:6d:fb:0e:3d -&gt; vxlan_over_ipv4/10.100.10.7

mcast-mac-local
  unknown-dst -&gt; vxlan_over_ipv4/10.100.10.7

</span></pre>
<div id="conclusion" class="section">
<h2>CONCLUSION</h2>
<p>We tested almost all scenarios for bare-metal connection to overlay networks on different devices. We proved that OpenContrail is working open source, multi-vendor SDN solution, which moves OpenStack cloud to the next level suitable for large enterprises.</p>
<p>In future parts of this blog we would like to look at High Availability setup of TOR agent, which has been added in Contrail 2.2. Our next post will focus on route gateways with functions like VxLAN to EVPN Stitching for L2 Extension, L3VPN, multi-vendor support and gateway redundancy.</p>
<div class="line-block">
<p class="line"><strong>Marek Celoud &amp; Jakub Pavlik</strong><br />
tcp cloud engineers</p>
</div>
<div class="line-block">
<p class="line"><strong>Rostislav Safar</strong><br />
Arrow ECS network engineer</p>
</div>
</div>
<div id="resources" class="section">
<h2>RESOURCES</h2>
<table id="contrailtor" class="docutils citation" frame="void" rules="none">
<colgroup>
<col class="label" />
<col /></colgroup>
<tbody valign="top">
<tr>
<td class="label">[ContrailToR]</td>
<td><em>(<a class="fn-backref" href="http://tcpcloud.eu/en/blog/2015/07/13/opencontrail-sdn-lab-testing-1-tor-switches-ovsdb/#id1">1</a>, <a class="fn-backref" href="http://tcpcloud.eu/en/blog/2015/07/13/opencontrail-sdn-lab-testing-1-tor-switches-ovsdb/#id2">2</a>)</em> Using TOR Switches with OVSDB for Virtual Instance Support <a href="http://www.juniper.net/techpubs/en_US/contrail2.2/topics/concept/using-tor-ovsdb-contrail.html" target="_blank">http://www.juniper.net/techpubs/en_US/contrail2.2/topics/concept/using-tor-ovsdb-contrail.html</a></td>
</tr>
</tbody>
</table>
<table id="torha" class="docutils citation" frame="void" rules="none">
<colgroup>
<col class="label" />
<col /></colgroup>
<tbody valign="top">
<tr>
<td class="label">[TorHA]</td>
<td>High Availability for Contrail TOR Agent <a href="http://www.juniper.net/techpubs/en_US/contrail2.2/topics/concept/ha-tor-agnt.html" target="_blank">http://www.juniper.net/techpubs/en_US/contrail2.2/topics/concept/ha-tor-agnt.html</a></td>
</tr>
</tbody>
</table>
<table id="site" class="docutils citation" frame="void" rules="none">
<colgroup>
<col class="label" />
<col /></colgroup>
<tbody valign="top">
<tr>
<td class="label"><a class="fn-backref" href="http://tcpcloud.eu/en/blog/2015/07/13/opencontrail-sdn-lab-testing-1-tor-switches-ovsdb/#id3">[site]</a></td>
<td>Juniper Contrail documentation <a href="http://www.juniper.net/techpubs/en_US/contrail2.2/topics/task/installation/install-overview-vnc.html" target="_blank">http://www.juniper.net/techpubs/en_US/contrail2.2/topics/task/installation/install-overview-vnc.html</a></td>
</tr>
</tbody>
</table>
<table id="vtep" class="docutils citation" frame="void" rules="none">
<colgroup>
<col class="label" />
<col /></colgroup>
<tbody valign="top">
<tr>
<td class="label"><a class="fn-backref" href="http://tcpcloud.eu/en/blog/2015/07/13/opencontrail-sdn-lab-testing-1-tor-switches-ovsdb/#id4">[vtep]</a></td>
<td>How to Use the VTEP Emulator <a class="reference external" href="https://github.com/openvswitch/ovs/blob/master/vtep/README.ovs-vtep.md">https://github.com/openvswitch/ovs/blob/master/vtep/README.ovs-vtep.md</a></td>
</tr>
</tbody>
</table>
<table id="ovscontrail" class="docutils citation" frame="void" rules="none">
<colgroup>
<col class="label" />
<col /></colgroup>
<tbody valign="top">
<tr>
<td class="label">[ovscontrail]</td>
<td>Setting up openvswitch VM for Contrail Baremetal <a class="reference external" href="https://github.com/Juniper/contrail-test/wiki/Setting-up-an-openvswitch-VM-for-Contrail-Baremetal-tests">https://github.com/Juniper/contrail-test/wiki/Setting-up-an-openvswitch-VM-for-Contrail-Baremetal-tests</a></td>
</tr>
</tbody>
</table>
<table id="vxlanovsdb" class="docutils citation" frame="void" rules="none">
<colgroup>
<col class="label" />
<col /></colgroup>
<tbody valign="top">
<tr>
<td class="label">[vxlanovsdb]</td>
<td>Enhancing VM mobility with VxLAN OVSDB <a class="reference external" href="http://mcleonard.blogspot.cz/2013/12/enhancing-vm-mobility-with-vxlan-ovsdb.html">http://mcleonard.blogspot.cz/2013/12/enhancing-vm-mobility-with-vxlan-ovsdb.html</a></td>
</tr>
</tbody>
</table>
<table id="ovslibvirt" class="docutils citation" frame="void" rules="none">
<colgroup>
<col class="label" />
<col /></colgroup>
<tbody valign="top">
<tr>
<td class="label">[ovslibvirt]</td>
<td>Libvirt configuration with openvswitch <a class="reference external" href="https://github.com/openvswitch/ovs/blob/master/INSTALL.Libvirt.md">https://github.com/openvswitch/ovs/blob/master/INSTALL.Libvirt.md</a></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Heat Application Stack in OpenContrail</title>
		<link>https://tungsten.io/heat-application-stack-in-opencontrail/</link>
		
		<dc:creator><![CDATA[Jakub Pavlik]]></dc:creator>
		<pubDate>Mon, 12 Jan 2015 19:41:33 +0000</pubDate>
				<category><![CDATA[Automation]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://www.opencontrail.org/?p=5944</guid>

					<description><![CDATA[Note: This is a post taken from tcpcloud blog co-authored by Ales Komarek &#38; Jakub Pavlik. Click here for the original post. In this blog we would like to show how...]]></description>
										<content:encoded><![CDATA[<p><strong>Note</strong>: This is a post taken from tcpcloud blog co-authored by Ales Komarek &amp; Jakub Pavlik. <a href="http://tcpcloud.eu/en/blog/2015/01/12/heat-application-stack-opencontrail/">Click here</a> for the original post.</p>
<p>In this blog we would like to show how to orchestrate with OpenStack using <a style="font-weight: inherit; font-style: inherit;" href="https://wiki.openstack.org/wiki/Heat">Heat</a> and OpenContrail. We show how to create complex application stack with using existing implementation HAProxy Neutron LbaaS in OpenContrail.</p>
<p>Heat is the main project of the OpenStack orchestration program. It allows users to describe deployments of complex cloud applications in text files called templates. These templates are then parsed and executed by the Heat engine.</p>
<p>Heat is not officially supported by Juniper in Contrail release 1.2, but with OpenStack release IceHouse it works smoothly for standard OpenStack resources. Contrail specific Heat resources can be implemented through contrail-heat repo at following link <a style="font-weight: inherit; font-style: inherit;" href="https://github.com/Juniper/contrail-heat">https://github.com/Juniper/contrail-heat</a></p>
<p>The contrail heat extensions adds resources for managing:</p>
<ul>
<li style="font-style: inherit;">Network IPAMs &#8211; IP Address Management resources, which are available only in OpenContrail.</li>
<li style="font-style: inherit;">Network Policies</li>
<li style="font-style: inherit;">Service Instance &#8211; orchestration for service channing in OpenContrail</li>
<li style="font-style: inherit;">etc.</li>
</ul>
<h2 style="font-weight: 400;"><span style="font-weight: inherit; font-style: inherit;">HEAT OPENCONTRAIL INSTALLATION</span></h2>
<p>Deploy latest stable OpenContrail release 1.2 with OpenStack IceHouse on Ubuntu 12.04 or 14.04 (e.g. <a style="font-weight: inherit; font-style: inherit;" href="http://www.opencontrail.org/deploy-opencontrail/">http://www.opencontrail.org/deploy-opencontrail/</a> ).</p>
<p>Add Cloud Archive IceHouse repository or download heat packages manually.</p>
<pre><span style="font-family: 'courier new', courier;"># apt-get install python-software-properties
# add-apt-repository cloud-archive:icehouse</span></pre>
<p>Install heat packages</p>
<pre><span style="font-family: 'courier new', courier;"># apt-get install heat-api heat-api-cfn heat-api-cloudwatch heat-engine heat-common python-heatclient</span></pre>
<p>Output should look like</p>
<pre><span style="font-family: 'courier new', courier;">
# dpkg -l | grep heat
ii  heat-api                         2014.1.3-0ubuntu1                     all          OpenStack orchestration service - ReST API
ii  heat-api-cfn                  2014.1.3-0ubuntu1                     all          OpenStack orchestration service - CFN API
ii  heat-api-cloudwatch   2014.1.3-0ubuntu1                     all          OpenStack orchestration service - CloudWatch API
ii  heat-common               2014.1.3-0ubuntu1                     all          OpenStack orchestration service - common files
ii  heat-engine                  2014.1.3-0ubuntu1                     all          OpenStack orchestration service - engine
ii  python-heat                 2014.1.3-0ubuntu1                     all          OpenStack orchestration service - Python files
ii  python-heatclient        0.2.8-0ubuntu1                           all          client library and CLI for OpenStack Heat</span></pre>
<p>Install contrail heat resources from github</p>
<pre><span style="font-family: 'courier new', courier;"># pip install git+https://github.com/Juniper/contrail-heat.git@R1.30</span></pre>
<p>In the configuration file, specify the location of the database where the Orchestration service stores data. Use same MySQL database as Contrail with a heat user on the controller node. Replace HEAT_DBPASS with the password for the database user. Edit /etc/heat/heat.conf and modify the [database] section:</p>
<pre><span style="font-family: 'courier new', courier;">[database]
# The SQLAlchemy connection string used to connect to the database
connection = mysql://heat:HEAT_DBPASS@controller/heat</span></pre>
<p>Use the password that you set previously to log in as root and create a heat database user:</p>
<pre><span style="font-family: 'courier new', courier;">
# mysql -u root -p
mysql&gt; CREATE DATABASE heat;
mysql&gt; GRANT ALL PRIVILEGES ON heat.* TO 'heat'@'localhost' \
IDENTIFIED BY 'HEAT_DBPASS';
mysql&gt; GRANT ALL PRIVILEGES ON heat.* TO 'heat'@'%' \
IDENTIFIED BY 'HEAT_DBPASS';</span></pre>
<p>Create the heat service tables:</p>
<pre><span style="font-family: 'courier new', courier;"># su -s /bin/sh -c "heat-manage db_sync" heat</span></pre>
<p>Create a heat user and endpoints that the Orchestration service can use to authenticate with the Identity Service.</p>
<pre><span style="font-family: 'courier new', courier;">
# source /etc/contrail/openrc
# keystone user-create --name=heat --pass=HEAT_PASS  --email=heat@example.com
# keystone user-role-add --user=heat --tenant=service --role=admin
# keystone role-create --name heat_stack_user</span></pre>
<p>&nbsp;</p>
<pre><span style="font-family: 'courier new', courier;">
# keystone service-create --name=heat --type=orchestration --description="Orchestration"
# keystone endpoint-create \
--service-id=$(keystone service-list | awk '/ orchestration / {print $2}') \
--publicurl=http://controller:8004/v1/%\(tenant_id\)s \
--internalurl=http://controller:8004/v1/%\(tenant_id\)s \
--adminurl=http://controller:8004/v1/%\(tenant_id\)s
# keystone service-create --name=heat-cfn --type=cloudformation --description="Orchestration CloudFormation"
# keystone endpoint-create \
--service-id=$(keystone service-list | awk '/ cloudformation / {print $2}') \
--publicurl=http://controller:8000/v1 \
--internalurl=http://controller:8000/v1 \
--adminurl=http://controller:8000/v1</span></pre>
<p>Edit following parameters in /etc/heat.conf</p>
<pre><span style="font-family: 'courier new', courier;">
[DEFAULT]
...
# URL of the Heat metadata server. (string value)
heat_metadata_server_url = http://CONTROLLER_IP:8000
# URL of the Heat waitcondition server. (string value)
heat_waitcondition_server_url = http://CONTROLLER_IP:8000/v1/waitcondition
...
rabbit_host = CONTROLLER_IP
rabbit_user = RABBIT_USER
rabbit_password = RABBIT_PASS
...

[keystone_authtoken]
auth_host = controller
auth_port = 35357
auth_protocol = http
auth_uri = http://controller:5000/v2.0
admin_tenant_name = service
admin_user = heat
admin_password = HEAT_PASS

[ec2authtoken]
auth_uri = http://controller:5000/v2.0</span></pre>
<p>Restart heat services</p>
<pre><span style="font-family: 'courier new', courier;">
# service heat-api restart
# service heat-api-cfn restart
# service heat-engine restart</span></pre>
<p>Verify heat</p>
<pre><span style="font-family: 'courier new', courier;">
# heat list</span></pre>
<p>If there is nothing, it is OK. Otherwise something is wrong. Now we can start with our application stack deployment.</p>
<h2 style="font-weight: 400;"><span style="font-weight: inherit; font-style: inherit;">HEAT STACK DEPLOYMENT PROCESS</span></h2>
<p>This part will cover how did we implement the automated deployment process with heat and salt. It actually consist of only 2 phases. In the 1st the heat orchestration client creates the necessary resources. After all resources have been successfully created the 2nd phase is stated. It orchestrates services across the application stack in the right order, ie. the database services are installed before the application services that require them.</p>
<ol>
<li style="font-style: inherit;">Create infrastructure resources</li>
<li style="font-style: inherit;">Orchestrate compute services</li>
</ol>
<p>The following schema illustrates how this deployment process works with the OpenStack IaaS platform. Heat orchestration</p>
<p><img loading="lazy" decoding="async" class="aligncenter  wp-image-5945" src="http://www.opencontrail.org/wp-content/uploads/2015/01/heat_arch_level.png" alt="heat_arch_level" width="761" height="238" data-id="5945" /></p>
<p>The entire process for this test is processed by the Salt orchestration runner [1]. The following code shows simple salt orchestration runner for deploying and configuring our application heat stacks covered in next part.</p>
<pre><span style="font-family: 'courier new', courier;">
setup_host:
salt.state:
- tgt: 'master.tcpcloud.eu'
- sls:
- reclass.storage
- salt.master
- heat.client

cmd.run:
salt.function:
- tgt: 'master.tcpcloud.eu'
- arg:
- cd /srv/heat/env; source /root/keystonerc; ./create_stack.sh &lt;stack_name&gt; &lt;stack_env&gt;

configure_node:
salt.state:
- tgt: '*&lt;stack_env&gt;*'
- highstate: True</span></pre>
<p><span style="font-weight: inherit; font-style: inherit;">This functionality can be implemented by bash script or Jenkins job as well. So what does the salt runner do? First it gets the metadata and provisioning services (salt formulas) on the orchestration controller in shape, then it calls heat to create resources. Our script waits for the completion of the stack creation. Then finally the salt master is called to enforce entire service stack (salt highstate) on all newly created compute resources. With our simple stack we can do it in just one configuration step, for more complicated stacks more steps would be required.</span></p>
<h2 style="font-weight: 400;"><span style="font-weight: inherit; font-style: inherit;">OUT TESTING APPLICATION STACK</span></h2>
<p>We tested the capabilities of Heat with OpenContrail resources on multiple application stacks with 2 web services booted from block volumes with load balancer in front. We have several kind of resources that were needed to be created before we could start the configuration orchestration:</p>
<ul>
<li style="font-style: inherit;">Network: Private Neutron network where all instances, load balancers and router are connnected.</li>
<li style="font-style: inherit;">Public IP: Neutron Floating IP from public network pool tha is associated with the load balancers.</li>
<li style="font-style: inherit;">Router: Shared Neutron Router implementing SNAT for all compute nodes within the private network.</li>
<li style="font-style: inherit;">Security Group: Shared security/firewall rules for orchestration and application services.</li>
<li style="font-style: inherit;">Disk Volume: Cinder block device with server image of ubuntu trusty with cfntools preinstalled.</li>
<li style="font-style: inherit;">Server: Nova Compute Instance is virtual server booted from block device and connected to virtual network having specific firewall rules (and little more). We tested for block device IBM SVC and Hitachi VSP cinder drivers.</li>
<li style="font-style: inherit;">Load Balancer: OpenContrail implementation of Neutron LBaaS Resource, works as 2 separate HA proxies with balanced IP.</li>
</ul>
<p>The following schema shows our the heat stack within one testing tenant. There are multiple web Service infrastructures (A, B), each have the same resource definition in heat, just the metadata (environmental parameters) differs.</p>
<p><img loading="lazy" decoding="async" class="aligncenter  wp-image-5946" src="http://www.opencontrail.org/wp-content/uploads/2015/01/heat_service_level.png" alt="heat_service_level" width="699" height="245" data-id="5946" /></p>
<p>Following code shows the complete creation of our testing in heat. It’s in the new HOT format which is our opinion a good leap forward to better readability and usability of these templates.</p>
<pre><span style="font-family: 'courier new', courier;">
heat_template_version: 2013-05-23
description: Web Service Stack
parameters:
lb_pool_name:
type: string
description: Name of the loadbalancer
server01_name:
type: string
description: Name of the server01 - instance/volume
server02_name:
type: string
description: Name of the server02 - instance/volume
public_net_id:
type: string
description: ID of the public network
private_net_id:
type: string
description: ID of the private network
private_subnet_id:
type: string
description: ID of the private network subnet
server_flavor:
type: string
description: Instance type for the servers
default: m1.small
constraints:
- allowed_values: [m1.tiny, m1.small, m1.medium, m1.large]
volume_source:
type: string
description: Source volume for clonned volumes
resources:
server_volume_01:
type: OS::Cinder::Volume
properties:
name: { get_param: server01_name }
size: 20
source_volid: { get_param: server_volume }
server_instance_01:
type: OS::Nova::Server
properties:
block_device_mapping:
- volume_id: { get_resource: server_volume_01 }
device_name: vda
flavor: { get_param: server_flavor }
name: { get_param: server01_name }
networks:
- network: { get_param: private_net_id }
security_groups:
- default
user_data_format: RAW
user_data: |
#!/bin/bash -v
server_volume_02:
type: OS::Cinder::Volume
properties:
name: { get_param: server02_name }
size: 20
source_volid: { get_param: server_volume }
server_instance_02:
type: OS::Nova::Server
properties:
block_device_mapping:
- volume_id: { get_resource: server_volume_02 }
device_name: vda
flavor: { get_param: server_flavor }
name: { get_param: server02_name }
networks:
- network: { get_param: private_net_id }
security_groups:
- default
user_data_format: RAW
user_data: |
#!/bin/bash -v
neutron_ping_healt_monitor:
type: OS::Neutron::HealthMonitor
properties:
admin_state_up: True
delay: 20
max_retries: 10
timeout: 10
type: PING
neutron_pool:
type: OS::Neutron::Pool
properties:
admin_state_up: True
lb_method: ROUND_ROBIN
name: { get_param: lb_pool_name }
protocol: HTTP
monitors:
- { get_resource: neutron_ping_healt_monitor }
subnet_id: { get_param: private_subnet_id }
vip:
protocol_port: 80
admin_state_up: True
subnet: { get_param: vip_subnet_id }
neutron_pool_member_instance_01:
type: OS::Neutron::PoolMember
properties:
address: { get_attr: [ server_instance_01, first_address ] }
admin_state_up: True
pool_id: { get_resource: neutron_pool }
protocol_port: 80
weight: 1
neutron_pool_member_instance_02:
type: OS::Neutron::PoolMember
properties:
address: { get_attr: [ server_instance_02, first_address ] }
admin_state_up: True
pool_id: { get_resource: neutron_pool }
protocol_port: 80
weight: 1
neutron_floatingip:
type: OS::Neutron::FloatingIP
properties:
floating_network_id: { get_param: public_net_id }
port_id: { "Fn::Select" : [ "port_id", { get_attr: [ neutron_pool , vip ] } ] }</span></pre>
<p>For this template parameters that define the environment are needed. And are defined by the following YAML object.</p>
<pre><span style="font-family: 'courier new', courier;">
parameters:
public_net_id: &lt;uuid&gt;
private_net_id: &lt;uuid&gt;
private_subnet_id: &lt;uuid&gt;
lb_pool_name: web-stg-lb-pool
server01_name: web-stg01
server02_name: web-stg02
server_flavor: m1.small
volume_source: &lt;uuid&gt;</span></pre>
<h2 dir="ltr">GRAPHICAL USER INTERFACE</h2>
<p dir="ltr">Along the automated shell guns we can operate the stack using the horizon-based GUI. We have adapted the GUI to see</p>
<p dir="ltr"><img loading="lazy" decoding="async" class="aligncenter  wp-image-5949" src="http://www.opencontrail.org/wp-content/uploads/2015/01/heat_application_stack_OpenContrail_image3.png" alt="heat_application_stack_OpenContrail_image3" width="721" height="406" data-id="5949" /></p>
<p>As the Heat orchestration GUI has limited options it can be used for example by developers without deeper knowledge of underlying service stack to setup their working or staging environments.</p>
<p>The following screen shows application stack with 5 server instance booted from volumes, connected to the same network with router and 2 floating IP’s hidden above and below the graph borders.</p>
<p><img loading="lazy" decoding="async" class="aligncenter  wp-image-5950" src="http://www.opencontrail.org/wp-content/uploads/2015/01/heat_application_stack_OpenContrail_image4.png" alt="heat_application_stack_OpenContrail_image4" width="775" height="436" data-id="5950" /></p>
<h2 style="font-weight: 400;">CONCLUSION</h2>
<p>Setting up Heat templates can solve previously unsolvable issues in virtual infrastructure life-cycles and that is creation and deletion of not-compute resources that compute resources rely on (network and storage resources mostly). Heat allows to create expandable range of resources that are created exactly in the right order. The compute servers are part of the resource stack and can be created and directed to configuration management of your choice. We have used the Salt configuration tool, but tools like Puppet, Chef or Ansible can be used as well.</p>
<h2 style="font-weight: 400;">INFORMATION SOURCES</h2>
<ul>
<li style="font-style: inherit;"><a style="font-weight: inherit; font-style: inherit;" href="http://docs.saltstack.com/en/latest/topics/tutorials/states_pt5.html#orchestrate-runner">http://docs.saltstack.com/en/latest/topics/tutorials/states_pt5.html#orchestrate-runner</a></li>
</ul>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>The importance of Abstraction. The concept of &#8220;SDN as a Compiler&#8221;.</title>
		<link>https://tungsten.io/the-importance-of-abstraction-the-concept-of-sdn-as-a-compiler/</link>
		
		<dc:creator><![CDATA[Bruno Rijsman]]></dc:creator>
		<pubDate>Mon, 16 Dec 2013 21:27:52 +0000</pubDate>
				<category><![CDATA[Automation]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://opencontrail.org/?p=1001</guid>

					<description><![CDATA[OpenContrail consists of two parts.  One part is the virtual router (vRouter) which sits in the hypervisor of virtualized servers.  The other part is a logically centralized SDN controller which...]]></description>
										<content:encoded><![CDATA[<p style="text-align: justify;">OpenContrail consists of two parts.  One part is the virtual router (vRouter) which sits in the hypervisor of virtualized servers.  The other part is a logically centralized SDN controller which provides north bound REST APIs for managing the network.</p>
<p><span id="more-1001"></span></p>
<p style="text-align: justify;">The fact that the OpenContrail controller is logically centralized simplifies network management a lot.  Instead of having to manage lots of discrete devices, you have a single point of management.  (Whilst OpenContrail is <i>logically</i> centralized it is actually <i>physically</i> distributed: it is implemented as a cluster of nodes for high availability and scale-out.)</p>
<p style="text-align: justify;">But the <i>real</i> key advantage of OpenContrail is that it allows you to manage the network at a high level of abstraction.  That is the topic of this blog post.</p>
<p style="text-align: justify;">What does this rather academic sounding statement &#8220;<i>management at a high level of abstraction</i>&#8221; really mean?</p>
<p style="text-align: justify;">Traditionally, when you want to deploy some complex scenario such as a Layer 3 Virtual Private Network (L3VPN) you have to configure lots and lots of stuff.  You have to configure routing instances, route targets, route distinguishers, import and export policies, interfaces, BGP, RSVP, etc. etc. etc.  All of these configuration statements are at a really low level of abstraction.  Instead of telling the routers <i>what</i> it is you are trying to achieve, you are giving the routers an excruciatingly detailed description of <i>how</i> to achieve it.  These configurations can become very complex and large; it is not uncommon to have hundreds or even thousands of configuration statements on each individual router.  In fact, at large service providers I have seen routers which multiple <i>hundreds of thousands </i>of lines of configuration.  I&#8217;m not exaggerating.</p>
<p style="text-align: justify;">Not so with OpenContrail.  The north-bound REST APIs provided by OpenContrail expose concepts at a much higher level of abstraction.  These are APIs at the service layer instead of the technology layer.  You instruct OpenContrail <i>what</i> to do, rather than <i>how </i>to do it.</p>
<p style="text-align: justify;">Let&#8217;s give some concrete examples to illustrate this concept.  Using combination of OpenContrail and OpenStack REST APIs calls you can do things such as:</p>
<ul style="text-align: justify;">
<li>Create virtual networks.</li>
<li>Create tenant Virtual Machines (VMs) and attach them to virtual networks.  Virtual machines connected to the same virtual network can communicate with each other.</li>
<li>Create policies and apply them at the boundary of two virtual networks.  This allows virtual machines on different virtual networks to communicate with each other subject to the rules and constraints expressed in the policy.</li>
<li>Create service virtual machines, also known as Virtual Network Functions (VNFs), such as for example a virtual firewall.  Policies can force traffic to be steered through one or a sequence of service virtual machines.  This is referred to as a service chaining.</li>
<li>Connect virtual networks to physical networks or to bare metal servers through using a gateway router or switch.</li>
</ul>
<p style="text-align: justify;">The following figure illustrates how the individual &#8220;Lego blocks&#8221; of virtual networks, virtual machines, policies, and gateways can be combined into some useful assembly.</p>
<p style="text-align: center;" align="center"><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5749" src="http://www.opencontrail.org/wp-content/uploads/2013/12/bruno_1216_blogpost_image1.png" alt="bruno_1216_blogpost_image1" width="609" height="215" data-id="5749" /><br clear="ALL" /> Figure 1: Service Layer Abstraction</p>
<p style="text-align: justify;">Two important observations on the north-bound REST APIs:</p>
<ul style="text-align: justify;">
<li>All of these things can also be done through the Graphical User Interface (GUI) which is simply an application on top of the REST APIs.</li>
<li>Upcoming release 1.03 OpenContrail will provide REST APIs which are compatible with Amazon Web Services (AWS) <a href="http://aws.amazon.com/ec2/">Elastic Compute Cloud (EC2)</a> and <a href="http://aws.amazon.com/vpc/">Virtual Private Cloud (VPC)</a>.  This makes it easy to migrate workloads back and forth between a private cloud implemented with Contrail and a public cloud with AWS EC2 and VPC compatible APIs.</li>
</ul>
<p style="text-align: justify;">Now, what does OpenContrail actually do under the hood to implement these service layer abstractions?  Most users will say, <a href="http://www.youtube.com/watch?v=GQ5ICXMC4xY">as Clark Gable famously said in <i>Gone with the Wind</i></a>: &#8220;Frankly, my dear, I don&#8217;t give a damn.&#8221;  This is the beauty of OpenContrail.  It allows users to manage their network at a high level of abstraction, using only concepts like virtual networks, virtual machines, policies and gateways.  When we say manage, we don&#8217;t only mean configuration but also operational state and analytics.  Most users neither care nor need to know how things actually work under the hood.</p>
<p style="text-align: justify;">The nice thing about having a high level of abstraction is that it allows users to create virtual networks and to interconnect virtual networks with policies without needing a deep knowledge of networking.  This is not just a nice benefit for operators &#8211; it is a crucial requirement for allowing cloud tenant to self-manage their own virtual networks.</p>
<p style="text-align: justify;">That said, some small minority of people, e.g. the network operations team, does care and does need to know.</p>
<p style="text-align: justify;">These abstractions can be implemented in multiple ways.  For example, historically data centers have used VLANs to implement virtual networks.  And in Research and Education (R&amp;E) environments it is popular to use OpenFlow for what is typically called network slicing in those environments.</p>
<p style="text-align: justify;">For various scaling and stability reasons (which are explained in the white paper <a href="http://www.juniper.net/us/en/local/pdf/whitepapers/2000515-en.pdf">&#8220;Proactive Overlay versus Reactive Hop-by-Hop &#8211; Juniper&#8217;s Motivations for the Contrail Architecture Explained.&#8221;</a>) the industry as a whole is converging on using &#8220;proactive overlays&#8221; for network virtualization in large scale deployments.  There is an <a href="http://www.youtube.com/watch?v=e_hqDFUOTTw">excellent tutorial on overlay networking by Ivan Pepelnjak</a> on YouTube. (Gratuitous plug: Ivan also runs the <a href="http://www.ipspace.net">ipspace.net</a> website where you can follow his blog posts and <a href="http://www.ipspace.net/Subscription_to_ioshints_webinars">subscribe to all of his truly excellent webinars</a> &#8211; at just under $200 per year it is an excellent value and highly recommended.)</p>
<p style="text-align: justify;"><br clear="ALL" /> In order to implement the service layer abstractions shown in figure 1 above, the OpenContrail SDN controller uses XMPP to communicate with virtual routers (vRouters) and uses BGP to communicate with physical gateway routers and switches.  The OpenContrail SDN controller creates all the right routing instances in the right places, creates all the right overlay tunnels in the right places, puts all the right routes in the right forwarding tables, etc. etc. etc. to implement the required service layer abstractions.  This is illustrated in the following figure.</p>
<p align="center"><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5750" src="http://www.opencontrail.org/wp-content/uploads/2013/12/bruno_1216_blogpost_image2.png" alt="bruno_1216_blogpost_image2" width="485" height="583" data-id="5750" /></p>
<p align="center">Figure 2: Technology Layer Implementation</p>
<p style="text-align: justify;">Even though this example only contains a handful of servers, virtual machines, and gateways, it is already starting to look like a bowl of spaghetti.  Just imagine what this diagram would have looked like if we had thousands of servers and tens of thousands of virtual machines.  It would be a nightmare to configure that manually.</p>
<p style="text-align: justify;">But that&#8217;s exactly what we used to do before automation and SDN. Before SDN introduced logically centralized APIs at a high level of abstraction, we used to configure networks at this low level of abstraction.  Now, with OpenContrail, all of this complexity gets automatically created under the hood.  The only thing you need to do is to instantiate the service layer abstractions as shown in figure 1.</p>
<p style="text-align: justify;">What&#8217;s the magic in OpenContrail that achieves this?  How is OpenContrail able to figure out how to translate the high level abstractions into low level operations on the network?</p>
<p style="text-align: justify;">OpenContrail uses a combination of formal data models and a transformation engine to accomplish this.  This is illustrated in figure 3 below.</p>
<p><img loading="lazy" decoding="async" class="size-full wp-image-5751 aligncenter" src="http://www.opencontrail.org/wp-content/uploads/2013/12/bruno_1216_blogpost_image3.png" alt="bruno_1216_blogpost_image3" width="564" height="420" data-id="5751" /></p>
<p style="text-align: center;"><span style="text-align: center;">Figure 3: Data Models and Transformation Engine</span></p>
<p style="text-align: justify;">OpenContrail contains a data model which describes the high level service layer abstractions.  This data model contains objects such as virtual networks, virtual machines, and policies.  The objects in the service data model can be created, modified, deleted, and queried using north bound REST APIs.  In fact, the north bound REST APIs are automatically generated from this data model.</p>
<p style="text-align: justify;">OpenContrail also contains another data model which describes the low level technology implementation details.  Here we have objects such as routing instances, route targets, etc.</p>
<p style="text-align: justify;">Between the service data model and the technology data model sits a transformation engine.</p>
<p style="text-align: justify;">The transformation engine is responsible for translating the service data model to the technology data model.  When you invoke the north bound REST APIs to instantiate a virtual network object in the service data model, the transformation engine wakes up and figures out &#8220;Hmmm&#8230;. you way you want a virtual network. That means I need to create these routing instances over here, and those overlay tunnels over there, and I need to put these routes in those routing instances.&#8221;  The transformation engine then instantiates objects in the technology data model to represent the existence of those low level objects.</p>
<p style="text-align: justify;">At this point, nothing has actually happened yet in the network.  The only thing we have done so far is that we have created a more detailed description of the desired state of the network.</p>
<p style="text-align: justify;">The south bound protocols fill this last remaining gap.  These south bound protocols listen for changes in the technology data model and are responsible for &#8220;<a href="http://www.youtube.com/watch?v=-ZxHAZChcYU">making it so</a>&#8221; in the network.  There are multiple south bound protocols, each responsible for particular subsets of the technology data model.  For example, the XMPP south bound protocol is responsible for populating routes in virtual routers whereas the BGP south bound protocol is responsible for populating routes in physical gateway routers and switches.</p>
<p style="text-align: justify;">The above description is somewhat idealized and simplified.  In reality we can have a hierarchy of multiple layers of abstractions.  Each time something changes in the top layer of abstraction it percolates down the layers until it reaches the bottom of the hierarchy at which point the south bound protocols push it into the network.</p>
<p style="text-align: justify;">OpenContrail uses a publish subscribe (&#8220;pubsub&#8221;) <a href="http://en.wikipedia.org/wiki/IF-MAP">IF-MAP</a> message bus to choreograph the sequence of events.  Changes in the service data model generate events.  The transformation engine subscribes to these events and executes transformation rules when these events occur.  Those transformation rules make changes in the technology data model, which also generates events.  Each south bound protocol subscribes to events for particular subsets of the technology data model.  When those events occur, the relevant south bound protocol (e.g. XMPP or BGP) is woken up and it sends a message to the relevant network device to implement the change.</p>
<p style="text-align: justify;">The fact that OpenContrail uses a pubsub message bus is one of the reasons why it can massively scale out.  Publishers and subscribers can be distributed across multiple nodes which communicate events with each other using the message bus.</p>
<p style="text-align: justify;">The OpenContrail uses the term &#8220;SDN as a Compiler&#8221; to describe this architecture.  You can think of the service data model as a high level programming language (e.g. Java or Scala).  You can think of the technology data model as a low level programming language (e.g. bytecode or assembly).  You can think of the transformation engine as a compiler which is responsible for &#8220;compiling&#8221; the service data model into the technology data model.  It&#8217;s a very fancy compiler though &#8211; it is an event-driven incremental Just In Time (JIT) compiler.</p>
<p style="text-align: justify;">Up until now we have described everything in terms of configuration.  However, something similar happens in the reverse direction for operational state and analytics.  The south bound protocols are responsible for collecting operational state and analytics events from the network.  The transformation engine is responsible for correlating and aggregating these low level states and events into more meaningful information at the service layer.</p>
<p style="text-align: justify;">For example, the Contrail virtual routers (vRouters) generate analytics events for every individual flow in the network.  The analytics nodes in the Contrail SDN controller contain collectors which store all of these events in a horizontally scalable distributed database.  They also contain a query engine which allow you to ask service layer questions such as &#8220;what was the total amount of traffic from virtual network A to virtual network B between 9am and 10am this morning?&#8221;</p>
<p style="text-align: justify;">For some use cases it even makes sense for the transformation engine to take not just configuration state as input but also operational state.  This creates feedback loops as shown in 3 above.</p>
<p style="text-align: justify;">For example, in a traffic engineering use case we combine the bandwidth demand matrix (high level configuration state), the administrative constraints (high level configuration state), the current topology of the network (high level operational state), and the current amount of traffic on the network (high level operational state) to compute a globally optimal set of paths e.g. LSPs (low level configuration state).  Those LSPs are instantiated in the network using a south bound protocol (e.g. <a href="http://tools.ietf.org/html/rfc5440">PCEP</a>).  Other south bound protocols are responsible for collecting the operational state (e.g. <a href="https://datatracker.ietf.org/doc/draft-gredler-bgp-te/">BGP-TE</a> for topology discovery and netflow for traffic measurement).</p>
<p style="text-align: justify;">The current use cases implemented in Contrail don&#8217;t involve such feedback loops yet.  When those uses cases are introduced we will get into some interesting control theory and stability questions.  This would be a great area for academic research.</p>
<p style="text-align: justify;">One of key points to take away from all of this is that OpenContrail is not just a point product to solve a particular set of specific use cases such as network virtualization and service chaining.  OpenContrail is actually a massively scalable framework for dynamic network management and control.</p>
<p style="text-align: justify;">We actively encourage the open source community to extend OpenContrail for other additional use cases by extending the high level data model with new types of services, by extending the low level data model with new types of technologies, by implementing new south bound protocols to push those new technology objects into the network, and by introducing new rules in the transformation engine.</p>
<p style="text-align: justify;">Here are some pointers into the OpenContrail code which is available in the<a href="https://github.com/Juniper/contrail-controller"> Juniper/contrail-controller Github repository</a> to get you started.</p>
<p style="text-align: justify;">The <a href="https://github.com/Juniper/contrail-controller/tree/master/src/schema">src/schema</a> directory contains all the data models, both the high level service data models and the low level technology data models.</p>
<p style="text-align: justify;">OpenContrail currently uses an XML-based data modeling language which is based on IF-MAP.  The data models are stored in XML Schema Definition (XSD) files which contain additional annotations in the form of structured comments (referred to as IFMAP-SEMANTICS-IDL).  The syntax and the semantics of those structured comments is described at the top of the file <a href="https://github.com/Juniper/contrail-controller/blob/master/src/schema/vnc_cfg.xsd">vnc_cfg.xsd</a>.</p>
<p style="text-align: justify;">As an example, here is an excerpt from the file <a href="https://github.com/Juniper/contrail-controller/blob/master/src/schema/vnc_cfg.xsd">vnc_cfg.xsd</a> which defines the virtual-machine object and the virtual-machine-interface object, and the relationship between them.</p>
<p style="text-align: center;" align="center"><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5753" src="http://www.opencontrail.org/wp-content/uploads/2013/12/bruno_1216_blogpost_image4.png" alt="bruno_1216_blogpost_image4" width="628" height="186" data-id="5753" /></p>
<p style="text-align: center;" align="center">Figure 4: Example Data Model</p>
<p style="text-align: justify;">An earlier blog post by Pedro Marques titled &#8220;<a href="http://opencontrail.org/adding-bgp-knob-to-opencontrail/">Adding a BGP knob to OpenContrail</a>&#8221; describes how to add a new element to the data model.</p>
<p style="text-align: justify;">The transformation engine rules are implemented as Python scripts in directory <a href="https://github.com/Juniper/contrail-controller/tree/master/src/config/schema-transformer">src/config/schema-transformer</a>.</p>
<p style="text-align: justify;">Each of the south bound protocols is stored in its own directory, for example directory <a href="https://github.com/Juniper/contrail-controller/tree/master/src/xmpp">src/xmpp</a> for XMPP and directory <a href="https://github.com/Juniper/contrail-controller/tree/master/src/bgp">src/bgp</a> for BGP.  The main function for the controller node in file <a href="https://github.com/Juniper/contrail-controller/blob/master/src/control-node/main.cc">src/control-node/main.cc</a> instantiates the south bound protocols.</p>
<p style="text-align: justify;">Phew! You&#8217;ve made it to the end of this very long blog post.  Hopefully you&#8217;ve learned something about the importance of having the right level of abstraction (namely a high level of abstraction) in the north bound interface provided by the SDN controller.  This isolates the applications running on the network from the vendor specific implementation details.  Using the concepts of transformation engines and &#8220;SDN as a Compiler&#8221; is not just elegant; it turns the SDN controller into a resilient, horizontally scalable, general purpose extensible platform for many current and future use cases.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Multi-tenant IaaS using OpenStack + OpenContrail</title>
		<link>https://tungsten.io/multi-tenant-iaas-using-openstack-opencontrail/</link>
		
		<dc:creator><![CDATA[Takashi Sogabe]]></dc:creator>
		<pubDate>Wed, 11 Dec 2013 09:07:12 +0000</pubDate>
				<category><![CDATA[Automation]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://opencontrail.org/?p=950</guid>

					<description><![CDATA[The following presentation was given by Takashi Sogabe, software engineer at Internet Initiative Japan, at an OpenStack Meetup in November.  Sogabe-san explored his testing of OpenStack and OpenContrail.  His slides...]]></description>
										<content:encoded><![CDATA[<p style="text-align: justify;">The following presentation was given by Takashi Sogabe, software engineer at Internet Initiative Japan, at an OpenStack Meetup in November.  Sogabe-san explored his testing of OpenStack and OpenContrail.  His slides are used with permission here.</p>
<p><span id="more-950"></span></p>
<p><a href="http://www.opencontrail.org/wp-content/uploads/2013/12/openstack-users-ja-sogabe-e.pdf">Multi-tenant IaaS using OpenStack + OpenContrail &#8211; PDF</a></p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Building and testing Layer2 Service Images for OpenContrail</title>
		<link>https://tungsten.io/building-and-testing-layer2-service-images-for-opencontrail/</link>
		
		<dc:creator><![CDATA[Hartmut Schroeder]]></dc:creator>
		<pubDate>Fri, 08 Nov 2013 23:10:53 +0000</pubDate>
				<category><![CDATA[Automation]]></category>
		<category><![CDATA[Gateway]]></category>
		<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">http://opencontrail.org/?p=645</guid>

					<description><![CDATA[1      Introduction This is a small introduction to service VM’s. On what the minimum requirements are to build them, and how to test them in a Fabric. Some people use...]]></description>
										<content:encoded><![CDATA[<h4>1      Introduction</h4>
<p>This is a small introduction to service VM’s. On what the minimum requirements are to build them, and how to test them in a Fabric. Some people use other names like Service-extraction, Service-chaining or Network Function Virtualisation (NFV) when they mean the whole construct. In this article, we’ll focus on what has to be done to create service VM’s, the extracted service that get’s this traffic and processes it, and how you can do simple tests with it.</p>
<p>An additional focus will be on the creation and testing of Layer 2 Forwarding Service Images since this is a bit more challenging compared to build-in a ‘traditional’ Layer 3 Forwarding Service Image.<br />
<span id="more-645"></span></p>
<h4> 2      Types of Service VM’s</h4>
<p>There are different types of service VM’s depending on what Layer 4 to Layer 7 service will be offered. When you build these VM’s, you must know how they fit into the network and how data traffic is passed through them for inspection or manipulation.</p>
<h5>2.1    Passive Collection of Data traffic or monitoring</h5>
<p><img loading="lazy" decoding="async" class="size-full wp-image-5786 aligncenter" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_2_1_image_1.png" alt="hartmut_blogpost_2_1_image_1" width="460" height="162" data-id="5786" /><span style="font-size: 13px;">A monitoring service VM get’s a configured amount of the traffic between two networks for analysis. The traffic in OpenContrail is selected by a Policy Rule, which can also be a part of a traffic analysis/debugging that resides inside the fabric. The rule may only select a portion of this traffic to be inspected by the service VM. The service VM itself does NOT manipulate or insert anything into the Data Traffic. It just observes the traffic; usually the interface is in a kind of Promiscuous Mode, and then can report events via the management interface to higher entities. For example, in sophisticated environments, the service VM can directly re-program the policies via the OpenContrail Controller API’s, based on an event seen, to stop malicious traffic.</span></p>
<h5>2.2    Service VM in-line with Data traffic</h5>
<p>Quite often you see Service VM’s that are in-line with the Data Traffic. This allows them to apply all kinds of manipulation of the Data traffic. Here are just a few of those applications that are in-line with the Data traffic:</p>
<ul>
<li>Caching Services</li>
<li>Firewalling Services</li>
<li>Tunnel Termination Service (mainly VPN-GWs of all types)</li>
<li>Traffic Shaping Services</li>
<li>Load-Balancing Services</li>
<li>Layer 7 inspection and Manipulation Services
<ul>
<li>HTTP Header</li>
<li>SQL Injection prevention</li>
<li>DPI</li>
</ul>
</li>
</ul>
<p>When you write these applications they usually have TWO or more interfaces to work within their environment. The Data Traffic is then manipulated or forwarded between those two interfaces. Should the Service Image for some reason NOT process the traffic then it is dropped or lost inside the Service VM, which it is not the case with the mirroring option but may be a desired behavior.</p>
<h5>2.3    Traffic forwarding Types</h5>
<h6>2.3.1    Layer 3 forwarding</h6>
<p><img loading="lazy" decoding="async" class="size-full wp-image-5788 aligncenter" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_2_3_1_image_1.png" alt="hartmut_blogpost_building_layer2_services_2_3_1_image_1" width="449" height="198" data-id="5788" /></p>
<p>Layer 3 forwarding is probably the most used option as a service VM. The service VM needs two interfaces; say eth0 and eth1; and should configure the interfaces via DHCP as with every other application that has usually just one interface into the network.</p>
<p>If the Service Guest is run on Linux as OS, then the only configuration option for a test-image (apart from the interface configuration) is to enable Kernel Forwarding. Below is a command that can be issued on a running VM or as part of a Cron-Job or /etc/rc.local configuration.</p>
<p><code>echo 1 &gt; /proc/sys/net/ipv4/ip_forward</code></p>
<h6>2.3.2    Layer 2 forwarding</h6>
<p><img loading="lazy" decoding="async" class="size-full wp-image-5789 aligncenter" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_2_3_2_image_1.png" alt="hartmut_blogpost_building_layer2_services_2_3_2_image_1" width="435" height="198" data-id="5789" /></p>
<p>Certain Service VM’s will not be able to do Layer 3 forwarding and will act as a Layer2 Bridge only. Which means all Forwarding they are doing is based on Layer 2 MAC basis and not on Layer 3 IP-Addresses. There are a number of reasons why a Service VM should do this. Mainly it’s about speed and simplicity of a Service or this is a Service that today exists in a Bump-In-The-Wire Appliance and is now hosted in a virtual environment.</p>
<h5>2.4    Optional management interfaces</h5>
<p>Management Interfaces are meant to provide an out-of-bound management of the Service VM. In some cases the Service VM has a fixed behaviour that is build-in with and started as soon as the orchestration system launches the VM. In those cases, a management interface may not be needed. On the other hand if the Service VM needs to communicate with higher management entities in the network such as OSS/BSS, then you would certainly want to configure such an interface.</p>
<h4> 3      Building a simple image for an Layer 2 in-line Service VM</h4>
<p>To build a Service Image for a Layer 2 forwarding VM we recommend building a regular Linux Image on KVM with virtio-support. This allows you to check the service in the same way it would later be used in OpenContrail.</p>
<p>In the example below we use a computer with three Ethernet NICs. The first eth0 will be used to access the system but is not mapped into the virtual machine. The Ethernet NICs eth1 and eth2 will be set into bridge mode and transparently appear in the Guest VM. This allows us to attach a regular service to these two interfaces before we load it into OpenContrail.</p>
<h5> 3.1    Building up the KVM install environment</h5>
<pre>Below are some simple instructions to install a KVM environment that allows you to install a VM into the KVM environment. On a desktop machine for a developer, this may have occurred in the past. Note the importance of installing the bridge-utils
 <code>
 <span style="font-family: 'courier new', courier;">yum -y install qemu-kvm libvirt python-virtinst</span>
<span style="font-family: 'courier new', courier;"> yum -y install virt-viewer virt-manager</span>
<span style="font-family: 'courier new', courier;"> yum -y groupinstall "Desktop" "Desktop Platform" "X Window System" "Fonts"</span>
<span style="font-family: 'courier new', courier;"> yum -y install bridge-utils tunctl</span>
<span style="font-family: 'courier new', courier;"> vi /etc/libvirt/qemu.conf</span>
<span style="font-family: 'courier new', courier;"> vnc_listen = "0.0.0.0"</span>
<span style="font-family: 'courier new', courier;"> user = "root"</span>
<span style="font-family: 'courier new', courier;"> group = "root"</span>
<span style="font-family: 'courier new', courier;"> dynamic_ownership = 1</span>
<span style="font-family: 'courier new', courier;"> service libvirtd restart</span></code></pre>
<h5> 3.2    Setting up local bridging</h5>
<p>The next step is to setup a local bridging to make the two interfaces eth1 and eth2 appear in the Guest VM so that we can use them.</p>
<pre><code><span style="font-family: 'courier new', courier;">brctl addbr br0</span>
<span style="font-family: 'courier new', courier;"> brctl addbr br1</span>
<span style="font-family: 'courier new', courier;"> brctl addif br0 eth1</span>
<span style="font-family: 'courier new', courier;"> brctl addif br1 eth2</span>
<span style="font-family: 'courier new', courier;"> brctl show</span>
<span style="font-family: 'courier new', courier;"> [root@sdn-cfgm ~]# brctl show</span>
<span style="font-family: 'courier new', courier;"> bridge name          bridge id           STP enabled           interfaces</span>
<span style="font-family: 'courier new', courier;"> br0                  8000.5cf3fcb79872   no                    eth1</span>
<span style="font-family: 'courier new', courier;"> br1                  8000.5cf3fc6a633c   no                    eth2</span>
<span style="font-family: 'courier new', courier;"> virbr0               8000.525400a2cfa0   yes                   virbr0-nic</span>
 </code></pre>
<h5> 3.3    Create and install the VM from ISO</h5>
<p>Below are instructions on how to create the image and start the installation process from an ISO in KVM. Our Image is called ‘guest’. Please review the network mapping.</p>
<pre><code><span style="font-family: 'courier new', courier;">qemu-img create -f qcow2 /var/lib/libvirt/images/guest.img 20G</span>
<span style="font-family: 'courier new', courier;"> virt-install --connect qemu:///system -n guest -r 4096 --vcpus=2 --disk path=/var/lib/libvirt/images/guest.img,format=qcow2,size=20,device=disk,bus=virtio -c /home/linux.iso --graphics vnc,listen=0.0.0.0 --os-type linux --hvm --network=bridge:br0,model=virtio --network=bridge:br1,model=virtio</span>
<span style="font-family: 'courier new', courier;"> Starting install...</span>
<span style="font-family: 'courier new', courier;"> Creating domain... | 0 B 00:00</span>
<span style="font-family: 'courier new', courier;"> Cannot open display:</span>
<span style="font-family: 'courier new', courier;"> Run 'virt-viewer --help' to see a full list of available command line options</span>
<span style="font-family: 'courier new', courier;"> Domain installation still in progress. You can reconnect to</span>
<span style="font-family: 'courier new', courier;"> the console to complete the installation process.</span>
<span style="font-family: 'courier new', courier;"> [root@sdn-cfgm ~]# virsh</span>
<span style="font-family: 'courier new', courier;"> Welcome to virsh, the virtualization interactive terminal.</span>
<span style="font-family: 'courier new', courier;"> Type: 'help' for help with commands</span>
<span style="font-family: 'courier new', courier;"> 'quit' to quit</span>
<span style="font-family: 'courier new', courier;"> virsh # list --all</span>
<span style="font-family: 'courier new', courier;"> Id Name State</span>
<span style="font-family: 'courier new', courier;"> ----------------------------------------------------</span>
<span style="font-family: 'courier new', courier;"> 2 guest running</span>
 </code></pre>
<p>At this point, the installation usually requires commands to choose the installation type and packages and so on. This is represented with a graphical view via the build-in VNC-Server that was also installed as part of the X-Windows installation. Please use a VNC-Client to finish the installation. With only one VM running, it’s usually window “:0” that has a view of this VM.</p>
<h5>3.4    Setup a simple Bridge inside a VM for testing</h5>
<p>Configuration of the services and of the interfaces inside the VM is left to the one developing the service and building the image. Below, we use a simple install of the (again) needed ‘bridge-utils’ and then we simply re-write /etc/rc.local with the shell commands that configures this bridge after the VM was started. You can do similar things for your own test-images before you start developing the Service.</p>
<pre><code><span style="font-family: 'courier new', courier;">yum -y install bridge-utils</span>
<span style="font-family: 'courier new', courier;"> cat &lt;/etc/rc.local</span>
<span style="font-family: 'courier new', courier;"> #!/bin/sh</span>
<span style="font-family: 'courier new', courier;"> #</span>
<span style="font-family: 'courier new', courier;"> # This script will be executed *after* all the other init scripts.</span>
<span style="font-family: 'courier new', courier;"> # You can put your own initialization stuff in here if you don’t</span>
<span style="font-family: 'courier new', courier;"> # want to do the full Sys V style init stuff.</span>
<span style="font-family: 'courier new', courier;"> touch /var/lock/subsys/local</span>
<span style="font-family: 'courier new', courier;"> ifconfig eth0 up</span>
<span style="font-family: 'courier new', courier;"> ifconfig eth1 up</span>
<span style="font-family: 'courier new', courier;"> brctl addbr mybridge</span>
<span style="font-family: 'courier new', courier;"> brctl addif mybridge eth0</span>
<span style="font-family: 'courier new', courier;"> brctl addif mybridge eth1</span>
<span style="font-family: 'courier new', courier;"> ifconfig eth0 0.0.0.0</span>
<span style="font-family: 'courier new', courier;"> ifconfig eth1 0.0.0.0</span>
<span style="font-family: 'courier new', courier;"> ifconfig mybridge up</span>
<span style="font-family: 'courier new', courier;"> EOF</span>
 </code></pre>
<h5>3.5    Finishing the Installation</h5>
<p>Please make sure that you gently halt the VM before you put it into production. Use “shutdown” and not “destroy” in virsh and wait until the VM is stopped.</p>
<p>There have been cases where the VM was not able to delete the file “/etc/udev/rules.d/70-persistent-net.rules”. This is especially the case when you use the un-gentle “destroy” command in virsh. When you then move this Image to an orchestration system (such as CloudStack or OpenStack) the MAC addresses of your Guest Interfaces change to the dynamic ones that are present inside the Guest. The original MAC addresses of the real interfaces we used to create the Image and test it are no longer available. An existing “/etc/udev/rules.d/70-persistent-net.rules” file that was not deleted may look like the previous interface name eth0 and eth1 inside the guest to the original MAC .  This will result in those Interfaces names no longer being available and having the OS use new ones like eth2 and eth3. To avoid this (especially if you have hardcoded scripts like the one above), you need to delete the file from the image before you read it into your orchestration system.</p>
<p>Below we use ‘guestfish’ to mount the image and delete the file. You can also use this method to make small changes to the configuration of the image later on via a simple text editor.</p>
<pre><code><span style="font-family: 'courier new', courier;">yum -y install guestfish</span>
<span style="font-family: 'courier new', courier;"> guestfish --rw -a /var/lib/libvirt/images/guest.img</span>
<span style="font-family: 'courier new', courier;"> &gt; run</span>
<span style="font-family: 'courier new', courier;"> &gt; list-filesystems</span>
<span style="font-family: 'courier new', courier;"> /dev/vda1: ext3</span>
<span style="font-family: 'courier new', courier;"> /dev/vda2: ext4</span>
<span style="font-family: 'courier new', courier;"> /dev/vda3: swap</span>
<span style="font-family: 'courier new', courier;"> /dev/vda4: unknown</span>
<span style="font-family: 'courier new', courier;"> /dev/vda5: ext4</span>
<span style="font-family: 'courier new', courier;"> &gt; mount /dev/vda2 /</span>
<span style="font-family: 'courier new', courier;"> &gt; rm /etc/udev/rules.d/70-persistent-net.rules</span>
<span style="font-family: 'courier new', courier;"> &gt; exit</span>
 </code></pre>
<p>The next step is an example to read -in the Image into OpenStack orchestration via CLI</p>
<pre><code><span style="font-family: 'courier new', courier;">source /etc/OpenContrail/openstackrc; glance add name='myservice' is_public=true container_format=ovf disk_format=qcow2</span>
<span style="font-family: 'courier new', courier;"> &lt; /var/lib/libvirt/images/guest.img</span>
 </code></pre>
<h4>4      Testing the Layer2 Service Image</h4>
<p>We’ll now do a test of the new Layer 2 service into an OpenContrail environment to see how it works.  To make this process easier, we use the same structure as above and use the OpenContrail GUI to test and make the relevant setup changes.</p>
<h5> 4.1    Setup the Virtual Networks</h5>
<p>First we create two internal virtual networks that are on the right and left side of the Service VM.</p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5790" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_1_image_1.png" alt="hartmut_blogpost_building_layer2_services_4_1_image_1" width="824" height="237" data-id="5790" /></p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5791" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_1_image_2.png" alt="hartmut_blogpost_building_layer2_services_4_1_image_2" width="748" height="312" data-id="5791" /></p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5792" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_1_image_3.png" alt="hartmut_blogpost_building_layer2_services_4_1_image_3" width="746" height="292" data-id="5792" /></p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5793" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_1_image_4.png" alt="hartmut_blogpost_building_layer2_services_4_1_image_4" width="1104" height="269" data-id="5793" /></p>
<h5>4.2    Create a Service-Template</h5>
<p>Now we need to create the Service Service-Template. It’s important to select Service-Mode=”Transparent” because this is the indicator for the system to know that this is a Layer 2 Service Image. The Service Type remains “firewall” indicating a Service VM that is in-line with the Data traffic.</p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5794" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_2_image_1.png" alt="hartmut_blogpost_building_layer2_services_4_2_image_1" width="879" height="279" data-id="5794" /><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5795" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_2_image_2.png" alt="hartmut_blogpost_building_layer2_services_4_2_image_2" width="554" height="400" data-id="5795" /></p>
<p>4.3    Launch a Service Image</p>
<p>Now we are launching our Service Image to be used.</p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5796" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_3_image_1.png" alt="hartmut_blogpost_building_layer2_services_4_3_image_1" width="707" height="292" data-id="5796" /></p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5797" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_3_image_2.png" alt="hartmut_blogpost_building_layer2_services_4_3_image_2" width="688" height="272" data-id="5797" /></p>
<p>In this step, it is VERY IMPORTANT to let the system use “Auto Configured” Networks because it needs to change the default behaviour of the vRouters at both ends in this network.</p>
<p>The default is that the vRouter uses the same MAC-Address towards any Guest VM regardless if it is a service VM or a normal application VM. The vRouter always has the MAC Address 00:01:00:5e:00:00 (which is IP-Multicast) that it uses towards the VM.</p>
<p>This design decision makes configuration easy if you think about things like mobility of a VM. No matter where you hold a running VM, copy it’s RAM and disk to a new server and spin it up again, the local vRouter will have the same local MAC address, which means that the migrated VM would never see any difference on the new server even if it was in a remote Data Center. The vRouter always shields the physical network from the Guest VM.</p>
<p>In this special environment we must change the behaviour of the vRouters. You need different MAC addresses at both ends; otherwise, the service VM might treat this as a Loop and no Traffic would flow. Choosing Auto-Configure lets the vRouter use a new MAC address as indicated in the capture below.</p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5798" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_3_image_3.png" alt="hartmut_blogpost_building_layer2_services_4_3_image_3" width="969" height="167" data-id="5798" /></p>
<p>Now the Orchestration System will start the Service VM<img loading="lazy" decoding="async" class="alignnone size-full wp-image-5799" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_3_image_4.png" alt="hartmut_blogpost_building_layer2_services_4_3_image_4" width="1325" height="286" data-id="5799" /></p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5800" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_3_image_5.png" alt="hartmut_blogpost_building_layer2_services_4_3_image_5" width="1088" height="248" data-id="5800" /></p>
<p>Ignore the IP-Address indicated as assigned to the VM. This may happen when the service VM ask for them via DHCP but this usually does not happen for Layer 2 Services.</p>
<h5>4.4    Create a Policy</h5>
<p>Now we need to create a Policy. This policy is similar to a Layer 3 service VM policy. You define the two networks Source/Destination for being left and right (don’t use the Auto-Configured Networks here). Check “Apply-Service” and select the running instance as below.<img loading="lazy" decoding="async" class="alignnone size-full wp-image-5801" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_4_image_1.png" alt="hartmut_blogpost_building_layer2_services_4_4_image_1" width="1084" height="342" data-id="5801" />4.5    Assign Policy to Network</p>
<p>Now you need to assign the policy to the networks. Below you also see also the new networks created via the Auto-Configure option. Just edit the old (left/right) networks to apply the policy.</p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5802" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_5_image_1.png" alt="hartmut_blogpost_building_layer2_services_4_5_image_1" width="1109" height="264" data-id="5802" /><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5803" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_5_image_2.png" alt="hartmut_blogpost_building_layer2_services_4_5_image_2" width="680" height="287" data-id="5803" /><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5804" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_5_image_3.png" alt="hartmut_blogpost_building_layer2_services_4_5_image_3" width="748" height="312" data-id="5804" /><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5805" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_5_image_4.png" alt="hartmut_blogpost_building_layer2_services_4_5_image_4" width="1098" height="343" data-id="5805" /></p>
<p>At this point the network configuration is ready to be tested.</p>
<h5>4.6    Test the Service Image</h5>
<p>Here we use OpenStack as the orchestration System. After we log into the project, we see the Service VM running on the Horizon Dashboard<img loading="lazy" decoding="async" class="alignnone size-full wp-image-5806" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_6_image_1.png" alt="hartmut_blogpost_building_layer2_services_4_6_image_1" width="1139" height="278" data-id="5806" /></p>
<p>For this demo, we just used an ordinary server image which has added bridge-utils support. After the orchestration system has started it, we need to login and manually configure, the same way as above, the Bridge.</p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5807" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_6_image_2.png" alt="hartmut_blogpost_building_layer2_services_4_6_image_2" width="598" height="286" data-id="5807" /></p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5808" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_6_image_3.png" alt="hartmut_blogpost_building_layer2_services_4_6_image_3" width="690" height="85" data-id="5808" /></p>
<p>Now we need to start two regular VM’s at both ends to be able to Ping each other through the Bridge Service.</p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5809" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_6_image_4.png" alt="hartmut_blogpost_building_layer2_services_4_6_image_4" width="762" height="697" data-id="5809" /></p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5810" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_6_image_5.png" alt="hartmut_blogpost_building_layer2_services_4_6_image_5" width="397" height="395" data-id="5810" /><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5811" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_6_image_6.png" alt="hartmut_blogpost_building_layer2_services_4_6_image_6" width="764" height="641" data-id="5811" /><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5812" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_6_image_7.png" alt="hartmut_blogpost_building_layer2_services_4_6_image_7" width="371" height="398" data-id="5812" /></p>
<p>After the two VM’s for our Test are started, just notify the two IP-Addresses they have to be able to ping each other.</p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5813" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_6_image_8.png" alt="hartmut_blogpost_building_layer2_services_4_6_image_8" width="648" height="368" data-id="5813" /></p>
<p>Now we login to the left VM in the left network and ping the right-VM</p>
<p><img loading="lazy" decoding="async" class="alignnone size-full wp-image-5814" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_6_image_9.png" alt="hartmut_blogpost_building_layer2_services_4_6_image_9" width="787" height="288" data-id="5814" /></p>
<p>The last thing is to check what we see in the Service VM. As you see below, our MAC based service runs perfectly and forwards traffic between both interfaces.<img loading="lazy" decoding="async" class="alignnone size-full wp-image-5815" src="http://www.opencontrail.org/wp-content/uploads/2013/11/hartmut_blogpost_building_layer2_services_4_6_image_10.png" alt="hartmut_blogpost_building_layer2_services_4_6_image_10" width="803" height="292" data-id="5815" />Now the rest is up for you to explore what new or existing services could be put in-between.</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
